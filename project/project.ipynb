{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZS0wkHPlyFO"
      },
      "source": [
        "# Final Project Notebook\n",
        "\n",
        "The report for this final project can be found at this [link](https://cybertraining-dsc.github.io/report/fa20-523-301/project/project/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvjolHp0lvEG"
      },
      "source": [
        "## Part 1 Importing the functions\n",
        "\n",
        "This file requires that we import Numpy, Matplotlib, Pylab, Keras, and Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBEQu5Gpl-eq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36YZ6mkT5iGO",
        "outputId": "552ae5fb-3345-4a73-f0b2-01f093836e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "! pip install cloudmesh-common -U\n",
        "\n",
        "from cloudmesh.common.Benchmark import Benchmark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloudmesh-common\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/cc/6b4baa73d00e9181fb75db453c62007c305294e3b07ee2cea7b3e1216219/cloudmesh_common-4.3.23-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.5MB/s \n",
            "\u001b[?25hCollecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pathlib in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (1.0.1)\n",
            "Collecting oyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/37/aa/111610d8bf5b1bb7a295a048fc648cec346347a8b0be5881defd2d1b4a52/oyaml-1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: humanize in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2018.9)\n",
            "Collecting python-hostlist\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/4f/f31dd4b4bf1a57a5c29599e1165d0df70dbdddcfa59a7c1d04ee2ff4ccbd/python-hostlist-1.21.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from oyaml->cloudmesh-common) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->cloudmesh-common) (1.15.0)\n",
            "Building wheels for collected packages: python-hostlist\n",
            "  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-hostlist: filename=python_hostlist-1.21-cp36-none-any.whl size=38932 sha256=a25e9079eacc1ecca8a4c6181cd0886448e602621778cae34beac90701ea7dc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/5b/55/ddcf52288f0b10f4564ca1b2531594ff7ccc65f487ba8dc437\n",
            "Successfully built python-hostlist\n",
            "Installing collected packages: simplejson, oyaml, python-hostlist, colorama, cloudmesh-common\n",
            "Successfully installed cloudmesh-common-4.3.23 colorama-0.4.4 oyaml-1.0 python-hostlist-1.21 simplejson-3.17.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntN4MMO7i02q",
        "outputId": "8abb1cbd-2e77-43ff-e2b3-0d8229c59ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! pip install utils\n",
        "import utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81DVIg2vo1t"
      },
      "source": [
        "Now that the funtions have been imported the team can focus on the download coding. The following cells will set up an install for Kaggle files and prompt for an upload of the kaggle.json file for credentials. \n",
        "\n",
        "The mkdir function creates a directory for the Kaggle data. This cell will allow the team to verify that the kaggle.json file appropriately uploaded to the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxduR8dEBwvz",
        "outputId": "ea3cf929-77a1-4051-ead8-91a89ed28af8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "##import the kaggle.json from local to drive\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "##when it asks you to choose a file select the kaggle.json located within the 'project' folder from the github repo\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7da3f8aa-b44f-4248-8dbf-087463d345ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7da3f8aa-b44f-4248-8dbf-087463d345ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"chelseagorius\",\"key\":\"0a34819ed937ff55d31f4288ab40cf19\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlgk1uL5D0Us",
        "outputId": "936085ba-f648-4b45-b012-98bb776d0e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "##make a kaggle and a data folder\n",
        "#!mkdir ~/.kaggle\n",
        "!mkdir data\n",
        "##copy the kaggle.json to the .kaggle folder then grant permissions\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#test to see if kaggle is working, should print list of datasets\n",
        "!kaggle datasets list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "ref                                                               title                                                 size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------------  --------------------------------------------------  ------  -------------------  -------------  \n",
            "nehaprabhavalkar/indian-food-101                                  Indian Food 101                                        7KB  2020-09-30 06:23:43           4577  \n",
            "christianlillelund/donald-trumps-rallies                          Donald Trump's Rallies                               720KB  2020-09-26 10:25:08           1141  \n",
            "heeraldedhia/groceries-dataset                                    Groceries dataset                                    257KB  2020-09-17 04:36:08           5107  \n",
            "andrewmvd/trip-advisor-hotel-reviews                              Trip Advisor Hotel Reviews                             5MB  2020-09-30 08:31:20           3079  \n",
            "balraj98/stanford-background-dataset                              Stanford Background Dataset                           17MB  2020-09-26 12:57:59            326  \n",
            "jilkothari/finance-accounting-courses-udemy-13k-course            Finance & Accounting Courses - Udemy (13K+ course)  1000KB  2020-09-17 12:46:12           1417  \n",
            "balraj98/massachusetts-roads-dataset                              Massachusetts Roads Dataset                            6GB  2020-09-26 03:57:49            266  \n",
            "arslanali4343/top-personality-dataset                             Top Personality Dataset                                9MB  2020-09-27 21:25:45           1774  \n",
            "oldaandozerskaya/fiction-corpus-for-agebased-text-classification  RusAge: Corpus for Age-Based Text Classification     509MB  2020-09-28 09:30:12            100  \n",
            "gpreda/chinese-mnist                                              Chinese MNIST                                         10MB  2020-08-05 12:36:00            575  \n",
            "gpreda/local-elections-romania-2020                               Local Elections Romania 2020                          28MB  2020-09-27 20:46:11            264  \n",
            "anth7310/mental-health-in-the-tech-industry                       Mental Health in the Tech Industry                     2MB  2020-09-27 11:17:23           2413  \n",
            "roshansharma/sanfranciso-crime-dataset                            Sanfranciso Crime Dataset                              6MB  2019-05-29 12:45:44           5340  \n",
            "bppuneethpai/tldr-summary-for-man-pages                           TLDR summary for man pages                             8MB  2020-09-25 09:50:10             68  \n",
            "sterby/german-recipes-dataset                                     German Recipes Dataset                                 5MB  2019-03-06 16:25:22           1022  \n",
            "arslanali4343/real-estate-dataset                                 Real Estate DataSet                                   12KB  2020-09-28 21:25:33           1974  \n",
            "leangab/poe-short-stories-corpuscsv                               E.A. Poe's corpus of short stories                   725KB  2020-09-28 11:43:08            189  \n",
            "thomaskonstantin/top-270-rated-computer-science-programing-books  Top 270 Computer Science / Programing Books           45KB  2020-09-28 16:47:12            895  \n",
            "anmolkumar/health-insurance-cross-sell-prediction                 Health Insurance Cross Sell Prediction 🏠 🏥             6MB  2020-09-11 18:39:31           5380  \n",
            "ramjidoolla/ipl-data-set                                          IPL _Data_Set                                          1MB  2020-09-14 10:57:42           5398  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKEX-7tbwMK-"
      },
      "source": [
        "Now, the team must download all of the datasets for the class. The three datasets are focused on the NBA. \n",
        "\n",
        "The first dataset is for injuries. Each injury will be used to set up players, timeframes, and severity of injuries. \n",
        "\n",
        "The other two datasets are for the player performance. By cross referencing this data to the previous list, the team will be able to see which players are limited from the injury and how performance is hampered by time in rehab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2QYBlpIEFBi",
        "outputId": "7987b000-94f3-426a-c06e-92b08c8be2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "##downloading all the datasets\n",
        "!kaggle datasets download -d ghopkins/nba-injuries-2010-2018\n",
        "!kaggle datasets download -d nathanlauga/nba-games\n",
        "!kaggle datasets download -d pablote/nba-enhanced-stats"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading nba-injuries-2010-2018.zip to /content\n",
            "\r  0% 0.00/226k [00:00<?, ?B/s]\n",
            "100% 226k/226k [00:00<00:00, 66.8MB/s]\n",
            "Downloading nba-games.zip to /content\n",
            " 50% 9.00M/18.1M [00:00<00:00, 27.7MB/s]\n",
            "100% 18.1M/18.1M [00:00<00:00, 40.8MB/s]\n",
            "Downloading nba-enhanced-stats.zip to /content\n",
            " 54% 9.00M/16.7M [00:00<00:00, 29.4MB/s]\n",
            "100% 16.7M/16.7M [00:00<00:00, 47.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3W0mASNHTs8",
        "outputId": "4f7d0b70-eae5-41e9-bba2-d3808eea5c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "##unzipping to the data folder\n",
        "!unzip nba-injuries-2010-2018.zip -d data\n",
        "!unzip nba-games.zip -d data\n",
        "!unzip nba-enhanced-stats.zip -d data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nba-injuries-2010-2018.zip\n",
            "  inflating: data/injuries_2010-2020.csv  \n",
            "Archive:  nba-games.zip\n",
            "  inflating: data/games.csv          \n",
            "  inflating: data/games_details.csv  \n",
            "  inflating: data/players.csv        \n",
            "  inflating: data/ranking.csv        \n",
            "  inflating: data/teams.csv          \n",
            "Archive:  nba-enhanced-stats.zip\n",
            "  inflating: data/2012-18_officialBoxScore.csv  \n",
            "  inflating: data/2012-18_playerBoxScore.csv  \n",
            "  inflating: data/2012-18_standings.csv  \n",
            "  inflating: data/2012-18_teamBoxScore.csv  \n",
            "  inflating: data/2016-17_officialBoxScore.csv  \n",
            "  inflating: data/2016-17_playerBoxScore.csv  \n",
            "  inflating: data/2016-17_standings.csv  \n",
            "  inflating: data/2016-17_teamBoxScore.csv  \n",
            "  inflating: data/2017-18_officialBoxScore.csv  \n",
            "  inflating: data/2017-18_playerBoxScore.csv  \n",
            "  inflating: data/2017-18_standings.csv  \n",
            "  inflating: data/2017-18_teamBoxScore.csv  \n",
            "  inflating: data/metadata_officialBoxScore.pdf  \n",
            "  inflating: data/metadata_playerBoxScore.pdf  \n",
            "  inflating: data/metadata_standing.pdf  \n",
            "  inflating: data/metadata_teamBoxScore.pdf  \n",
            "  inflating: data/teamBoxScore.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aIzY8a4wusX"
      },
      "source": [
        "The team must now use these downloads to create dataframes. Pandas dataframes will be easier to manage the data. The team will be able to use Pandas to process the data and allow the team to make correlations for feature engineering to create the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zmpmw-zImsz"
      },
      "source": [
        "#create a list for each data set\n",
        "ds_NBA_Injuries, ds_NBA_Games, ds_NBA_Enhanced = [], [], []\n",
        "\n",
        "#import csv files as dataframes and save to respective list, injury set first\n",
        "df_Injuries = pd.read_csv('data/injuries_2010-2020.csv')\n",
        "df_Injury_Start = df_Injuries[df_Injuries.Acquired.isnull()]\n",
        "df_Injury_End = df_Injuries[df_Injuries.Relinquished.isnull()]\n",
        "ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "#nba games dataset\n",
        "df_Games_games = pd.read_csv('data/games.csv')\n",
        "df_Games_gamesDetails = pd.read_csv('data/games_details.csv')\n",
        "df_Games_players = pd.read_csv('data/players.csv')\n",
        "df_Games_ranking = pd.read_csv('data/ranking.csv')\n",
        "df_Games_teams = pd.read_csv('data/teams.csv')\n",
        "ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]\n",
        "#nba enhanced stats dataset\n",
        "df_En_officialBS_1218 = pd.read_csv('data/2012-18_officialBoxScore.csv')\n",
        "df_En_playerBS_1218 = pd.read_csv('data/2012-18_playerBoxScore.csv')\n",
        "df_En_standings_1218 = pd.read_csv('data/2012-18_standings.csv')\n",
        "df_En_teamBS_1218 = pd.read_csv('data/2012-18_teamBoxScore.csv')  \n",
        "df_En_officialBS_1617 = pd.read_csv('data/2016-17_officialBoxScore.csv')  \n",
        "df_En_playerBS_1617 = pd.read_csv('data/2016-17_playerBoxScore.csv')\n",
        "df_En_standings_1617 = pd.read_csv('data/2016-17_standings.csv')\n",
        "df_En_teamBS_1617 = pd.read_csv('data/2016-17_teamBoxScore.csv')  \n",
        "df_En_officialBS_1718 = pd.read_csv('data/2017-18_officialBoxScore.csv')  \n",
        "df_En_playerBS_1718 = pd.read_csv('data/2017-18_playerBoxScore.csv')\n",
        "df_En_standings_1718 = pd.read_csv('data/2017-18_standings.csv')\n",
        "df_En_teamBS_1718 = pd.read_csv('data/2017-18_teamBoxScore.csv')  \n",
        "##data/metadata_officialBoxScore.pdf, data/metadata_playerBoxScore.pdf, data/metadata_standing.pdf, data/metadata_teamBoxScore.pdf  \n",
        "df_En_teamBS = pd.read_csv('data/teamBoxScore.csv')\n",
        "ds_NBA_Enhanced = [df_En_officialBS_1218, df_En_officialBS_1617, df_En_officialBS_1718, df_En_playerBS_1218, df_En_playerBS_1617, df_En_playerBS_1718, df_En_standings_1218, df_En_standings_1617, df_En_standings_1718, \\\n",
        "                       df_En_teamBS_1218, df_En_teamBS_1617, df_En_teamBS_1718, df_En_teamBS]\n",
        "\n",
        "\n",
        "#probably need some more data exploration and some feature engineering"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFpaEfk4w_DG"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "At this point, it is time to build into new useful sets of data. The team will explore different sets to combine in to the models to be trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHSB5EUzEbyO"
      },
      "source": [
        ""
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CviX4Qh0ASgW"
      },
      "source": [
        "#distinct player and player ID list\n",
        "df_distinct_playerID = df_Games_players[[\"PLAYER_NAME\", \"PLAYER_ID\"]].drop_duplicates()\n",
        "df_distinct_playerID.astype({'PLAYER_ID':'object'}).dtypes\n",
        "#distinct gameID and game date list\n",
        "df_Games_games['GAME_DATE_EST'] = pd.to_datetime(df_Games_games['GAME_DATE_EST'])\n",
        "df_distinct_gameId_date = df_Games_games[[\"GAME_ID\", \"GAME_DATE_EST\"]].drop_duplicates()\n",
        "#join player ID, for j=injury start db\n",
        "df_Injury_Start = df_Injury_Start.join(df_distinct_playerID.astype('object').set_index('PLAYER_NAME'), on='Relinquished')\n",
        "df_Injury_Start = df_Injury_Start.merge(df_Games_teams[[\"TEAM_ID\", \"NICKNAME\"]], left_on=\"Team\", right_on=\"NICKNAME\")\n",
        "df_Injury_Start.drop(['NICKNAME'], axis=1)\n",
        "df_Injury_Start['Date']= pd.to_datetime(df_Injury_Start['Date'])\n",
        "#again for injury end db\n",
        "df_Injury_End = df_Injury_End.join(df_distinct_playerID.astype('object').set_index('PLAYER_NAME'), on='Acquired')\n",
        "df_Injury_End = df_Injury_End.merge(df_Games_teams[[\"TEAM_ID\", \"NICKNAME\"]], left_on=\"Team\", right_on=\"NICKNAME\")\n",
        "df_Injury_End.drop(['NICKNAME'], axis=1)\n",
        "df_Injury_End['Date']= pd.to_datetime(df_Injury_Start['Date'])\n",
        "# df_distinct_playerID=df_distinct_playerID.sort_values('PLAYER_NAME')\n",
        "df_Games_gamesDetails = df_Games_gamesDetails.merge(df_distinct_gameId_date, on=\"GAME_ID\")\n",
        "\n",
        "# df_distinct_playerID = df_distinct_playerID.sort_values(by=['PLAYER_NAME']).reset_index(drop=True, inplace=True)\n",
        "#df_Injury_End"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3x_kS61EWVx",
        "outputId": "0143c9c2-2912-4140-d4fa-707c277bddb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "###TRYING TO SOLVE MINUTES FORMATTING\n",
        "\n",
        "\n",
        "#df_Games_gamesDetails[['MIN']].find(':')\n",
        "#int(inj_game['MIN'][:(inj_game['MIN'].find(':'))]) + (int(inj_game['MIN'][(inj_game['MIN'].find(':') +1):])/ 60)\n",
        "df_Games_gamesDetails['MIN'] = int(df_Games_gamesDetails['MIN'][:(df_Games_gamesDetails['MIN'].find(':'))]) + (int(df_Games_gamesDetails['MIN'][(df_Games_gamesDetails['MIN'].find(':') +1):])/ 60)"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-269-b578baec40e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df_Games_gamesDetails[['MIN']].find(':')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#int(inj_game['MIN'][:(inj_game['MIN'].find(':'))]) + (int(inj_game['MIN'][(inj_game['MIN'].find(':') +1):])/ 60)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'find'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE2TFbvCImtn",
        "outputId": "2dbc9a91-7ece-4b29-f58b-0e9b5d50f90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x = game_set1['GAME_ID']\n",
        "#x\n",
        "#y = df_Games_gamesDetails.loc[df_Games_gamesDetails['GAME_ID'].isin(x.values.tolist())]\n",
        "game_set2\n",
        "p_id\n",
        "game_set2.loc[game_set2['PLAYER_ID'].astype('int') == 2430]\n",
        "#game_set2['PLAYER_ID'].dtype\n",
        "#y.iloc[0]\n",
        "#temp.head(10)\n",
        "x = df_Games_gamesDetails.loc[(df_Games_gamesDetails['PLAYER_ID'] == row.PLAYER_ID) & (df_Games_gamesDetails['GAME_DATE_EST'] < row.Date)].nlargest(5, 'GAME_DATE_EST')[['MIN']]\n",
        "df_Injury_Start.loc[df_Injury_Start['Relinquished'] == \"Omer Asik\"]\n",
        "prior5['PLUS_MINUS'].mean()"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCknO5JCK-o"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGAu05JixyFQ",
        "outputId": "0dc72652-454a-42bb-f539-610324a3c151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#df_Injury_Start.Date\n",
        "\n",
        "for index, row in df_Injury_Start.iterrows():\n",
        "        #games of just that player\n",
        "        temp = df_Games_gamesDetails.loc[df_Games_gamesDetails['PLAYER_ID'] == row.PLAYER_ID]\n",
        "        #games before and inlucding injury date\n",
        "        inj_game = temp.loc[(temp['GAME_DATE_EST'] == row.Date)]\n",
        "        #5 games prior and the game of injury, for some reason we need to have 4 different variabels, did not work with resetting the variable 'game_set' to itself\n",
        "        temp2 = temp.loc[(temp['GAME_DATE_EST'] <= row.Date)]\n",
        "        game_set = temp2.nlargest(6, 'GAME_DATE_EST')\n",
        "        if len(game_set) > 0:\n",
        "          #injury game\n",
        "          inj_game = game_set.iloc[0]\n",
        "          #5 games prior to injury\n",
        "          prior5 = game_set.iloc[1:]\n",
        "          #storing game data from injury game\n",
        "          df_Injury_Start['inj_MIN'] = inj_game[['MIN']]\n",
        "          df_Injury_Start['inj_FGA'] = inj_game[['FGA']]\n",
        "          df_Injury_Start['inj_FG_PCT'] = inj_game[['FG_PCT']]\n",
        "          df_Injury_Start['inj_FG3A'] = inj_game[['FG3A']]\n",
        "          df_Injury_Start['inj_FG3_PCT'] = inj_game[['FG3_PCT']]\n",
        "          df_Injury_Start['inj_FTA'] = inj_game[['FTA']]\n",
        "          df_Injury_Start['inj_FT_PCT'] = inj_game[['FT_PCT']]\n",
        "          df_Injury_Start['inj_REB'] = inj_game[['REB']]\n",
        "          df_Injury_Start['inj_AST'] = inj_game[['AST']]\n",
        "          df_Injury_Start['inj_STL'] = inj_game[['STL']]\n",
        "          df_Injury_Start['inj_BLK'] = inj_game[['BLK']]\n",
        "          df_Injury_Start['inj_TO'] = inj_game[['TO']]\n",
        "          df_Injury_Start['inj_PF'] = inj_game[['PF']]\n",
        "          df_Injury_Start['inj_PTS'] = inj_game[['PTS']]\n",
        "          df_Injury_Start['inj_PLUS_MINUS'] = inj_game[['PLUS_MINUS']]\n",
        "          #storing game data from prior 5 games\n",
        "          df_Injury_Start['p5_MIN'] = prior5[['MIN']].mean()\n",
        "          df_Injury_Start['p5_FGA'] = prior5[['FGA']].mean()\n",
        "          df_Injury_Start['p5_FG_PCT'] = prior5[['FG_PCT']].mean()\n",
        "          df_Injury_Start['p5_FG3A'] = prior5[['FG3A']].mean()\n",
        "          df_Injury_Start['p5_FG3_PCT'] = prior5[['FG3_PCT']].mean()\n",
        "          df_Injury_Start['p5_FTA'] = prior5[['FTA']].mean()\n",
        "          df_Injury_Start['p5_FT_PCT'] = prior5[['FT_PCT']].mean()\n",
        "          df_Injury_Start['p5_REB'] = prior5[['REB']].mean()\n",
        "          df_Injury_Start['p5_AST'] = prior5[['AST']].mean()\n",
        "          df_Injury_Start['p5_STL'] = prior5[['STL']].mean()\n",
        "          df_Injury_Start['p5_BLK'] = prior5[['BLK']].mean()\n",
        "          df_Injury_Start['p5_TO'] = prior5[['TO']].mean()\n",
        "          df_Injury_Start['p5_PF'] = prior5[['PF']].mean()\n",
        "          df_Injury_Start['p5_PTS'] = prior5[['PTS']].mean()\n",
        "          df_Injury_Start['p5_PLUS_MINUS'] = prior5[['PLUS_MINUS']].mean()\n",
        "\n",
        "\n",
        "        #print(inj_game)\n",
        "        #print(prior5)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-239-382c4e896cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;31m#storing game data from prior 5 games\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p5_MIN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p5_FGA'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FGA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p5_FG_PCT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FG_PCT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p5_FG3A'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FG3A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \"\"\"\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3798\u001b[0m         \u001b[0;31m# broadcast across multiple columns if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3799\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mbroadcast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3800\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3801\u001b[0m                 \u001b[0mexisting_piece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4032\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4033\u001b[0m         \"\"\"\n\u001b[1;32m   4034\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EZjFydc7m5L"
      },
      "source": [
        "#df_Injury_End\n",
        "\n",
        "for index, row in df_Injury_End.iterrows():\n",
        "        #games of just that player\n",
        "        temp = df_Games_gamesDetails.loc[df_Games_gamesDetails['PLAYER_ID'] == row.PLAYER_ID]\n",
        "        #games before and inlucding injury date\n",
        "        temp2 = temp.loc[(temp['GAME_DATE_EST'] >= row.Date)]\n",
        "        #5 games prior and the game of injury, for some reason we need to have 4 different variabels, did not work with resetting the variable 'game_set' to itself\n",
        "        game_set = temp.nsmallest(6, 'GAME_DATE_EST')\n",
        "        if len(game_set) > 0:\n",
        "          #injury game\n",
        "          inj_game = game_set.iloc[0]\n",
        "          #5 games post injury\n",
        "          post5 = game_set.iloc[1:]\n",
        "          #storing game data from injury game\n",
        "          df_Injury_End['inj_MIN'] = inj_game[['MIN']]\n",
        "          df_Injury_End['inj_FGA'] = inj_game[['FGA']]\n",
        "          df_Injury_End['inj_FG_PCT'] = inj_game[['FG_PCT']]\n",
        "          df_Injury_End['inj_FG3A'] = inj_game[['FG3A']]\n",
        "          df_Injury_End['inj_FG3_PCT'] = inj_game[['FG3_PCT']]\n",
        "          df_Injury_End['inj_FTA'] = inj_game[['FTA']]\n",
        "          df_Injury_End['inj_FT_PCT'] = inj_game[['FT_PCT']]\n",
        "          df_Injury_End['inj_REB'] = inj_game[['REB']]\n",
        "          df_Injury_End['inj_AST'] = inj_game[['AST']]\n",
        "          df_Injury_End['inj_STL'] = inj_game[['STL']]\n",
        "          df_Injury_End['inj_BLK'] = inj_game[['BLK']]\n",
        "          df_Injury_End['inj_TO'] = inj_game[['TO']]\n",
        "          df_Injury_End['inj_PF'] = inj_game[['PF']]\n",
        "          df_Injury_End['inj_PTS'] = inj_game[['PTS']]\n",
        "          df_Injury_End['inj_PLUS_MINUS'] = inj_game[['PLUS_MINUS']]\n",
        "          #storing game data from prior 5 games\n",
        "          df_Injury_End['p5_MIN'] = post5[['MIN']].mean()\n",
        "          df_Injury_End['p5_FGA'] = post5[['FGA']].mean()\n",
        "          df_Injury_End['p5_FG_PCT'] = post5[['FG_PCT']].mean()\n",
        "          df_Injury_End['p5_FG3A'] = post5[['FG3A']].mean()\n",
        "          df_Injury_End['p5_FG3_PCT'] = post5[['FG3_PCT']].mean()\n",
        "          df_Injury_End['p5_FTA'] = post5[['FTA']].mean()\n",
        "          df_Injury_End['p5_FT_PCT'] = post5[['FT_PCT']].mean()\n",
        "          df_Injury_End['p5_REB'] = post5[['REB']].mean()\n",
        "          df_Injury_End['p5_AST'] = post5[['AST']].mean()\n",
        "          df_Injury_End['p5_STL'] = post5[['STL']].mean()\n",
        "          df_Injury_End['p5_BLK'] = post5[['BLK']].mean()\n",
        "          df_Injury_End['p5_TO'] = post5[['TO']].mean()\n",
        "          df_Injury_End['p5_PF'] = post5[['PF']].mean()\n",
        "          df_Injury_End['p5_PTS'] = post5[['PTS']].mean()\n",
        "          df_Injury_End['p5_PLUS_MINUS'] = post5[['PLUS_MINUS']].mean()\n",
        "\n",
        "\n",
        "        #print(inj_game)\n",
        "        #print(prior5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLp742E5ftIr"
      },
      "source": [
        "# Part 2 Building the Keras Model\n",
        "\n",
        "A link for Keras for us to use can be found [here](https://keras.io/guides/sequential_model/). We are first going to set up our Benchmark Test to be used when we are Benchmarking our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnUZ7nOe41w_"
      },
      "source": [
        "def b():\n",
        "  Benchmark.Start()\n",
        "  print (\"b\")\n",
        "  import time\n",
        "  time.sleep(3)\n",
        "  Benchmark.Stop()\n",
        "\n",
        "def c():\n",
        "  Benchmark.Start()\n",
        "  print (\"c\")\n",
        "  import time\n",
        "  time.sleep(1)\n",
        "  Benchmark.Stop()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c637S5T65JYz",
        "outputId": "fc462bc4-83a9-4807-d2e4-8300e359f3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        " b()\n",
        " c()\n",
        "\n",
        " Benchmark.print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\n",
            "c\n",
            "\n",
            "+---------------------+------------------------------------------------------------------+\n",
            "| Attribute           | Value                                                            |\n",
            "|---------------------+------------------------------------------------------------------|\n",
            "| BUG_REPORT_URL      | \"https://bugs.launchpad.net/ubuntu/\"                             |\n",
            "| DISTRIB_CODENAME    | bionic                                                           |\n",
            "| DISTRIB_DESCRIPTION | \"Ubuntu 18.04.5 LTS\"                                             |\n",
            "| DISTRIB_ID          | Ubuntu                                                           |\n",
            "| DISTRIB_RELEASE     | 18.04                                                            |\n",
            "| HOME_URL            | \"https://www.ubuntu.com/\"                                        |\n",
            "| ID                  | ubuntu                                                           |\n",
            "| ID_LIKE             | debian                                                           |\n",
            "| NAME                | \"Ubuntu\"                                                         |\n",
            "| PRETTY_NAME         | \"Ubuntu 18.04.5 LTS\"                                             |\n",
            "| PRIVACY_POLICY_URL  | \"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" |\n",
            "| SUPPORT_URL         | \"https://help.ubuntu.com/\"                                       |\n",
            "| UBUNTU_CODENAME     | bionic                                                           |\n",
            "| VERSION             | \"18.04.5 LTS (Bionic Beaver)\"                                    |\n",
            "| VERSION_CODENAME    | bionic                                                           |\n",
            "| VERSION_ID          | \"18.04\"                                                          |\n",
            "| cpu_count           | 2                                                                |\n",
            "| mem.active          | 994.3 MiB                                                        |\n",
            "| mem.available       | 11.6 GiB                                                         |\n",
            "| mem.free            | 9.3 GiB                                                          |\n",
            "| mem.inactive        | 2.1 GiB                                                          |\n",
            "| mem.percent         | 8.7 %                                                            |\n",
            "| mem.total           | 12.7 GiB                                                         |\n",
            "| mem.used            | 1.0 GiB                                                          |\n",
            "| platform.version    | #1 SMP Thu Jul 23 08:00:38 PDT 2020                              |\n",
            "| python              | 3.6.9 (default, Jul 17 2020, 12:50:27)                           |\n",
            "|                     | [GCC 8.4.0]                                                      |\n",
            "| python.pip          | 19.3.1                                                           |\n",
            "| python.version      | 3.6.9                                                            |\n",
            "| sys.platform        | linux                                                            |\n",
            "| uname.machine       | x86_64                                                           |\n",
            "| uname.node          | 1a0c36147294                                                     |\n",
            "| uname.processor     | x86_64                                                           |\n",
            "| uname.release       | 4.19.112+                                                        |\n",
            "| uname.system        | Linux                                                            |\n",
            "| uname.version       | #1 SMP Thu Jul 23 08:00:38 PDT 2020                              |\n",
            "| user                | collab                                                           |\n",
            "+---------------------+------------------------------------------------------------------+\n",
            "\n",
            "+-----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------+\n",
            "| Name                              | Status   |   Time |   Sum | Start               | tag   | Node         | User   | OS    | Version                             |\n",
            "|-----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------|\n",
            "| <ipython-input-12-124396bcabb3>/b | ok       |  3.029 | 3.029 | 2020-10-24 23:37:17 |       | 1a0c36147294 | collab | Linux | #1 SMP Thu Jul 23 08:00:38 PDT 2020 |\n",
            "| <ipython-input-12-124396bcabb3>/c | ok       |  1.022 | 1.022 | 2020-10-24 23:37:20 |       | 1a0c36147294 | collab | Linux | #1 SMP Thu Jul 23 08:00:38 PDT 2020 |\n",
            "+-----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------+\n",
            "\n",
            "# csv,timer,status,time,sum,start,tag,uname.node,user,uname.system,platform.version\n",
            "# csv,<ipython-input-12-124396bcabb3>/b,ok,3.029,3.029,2020-10-24 23:37:17,,1a0c36147294,collab,Linux,#1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "# csv,<ipython-input-12-124396bcabb3>/c,ok,1.022,1.022,2020-10-24 23:37:20,,1a0c36147294,collab,Linux,#1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wmn5BA8MGQ"
      },
      "source": [
        "Now that we know which GPU we are using, we can get into the actual work. The following is building our Keras model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQXCq-wldYs9"
      },
      "source": [
        "#TO ADD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-TMhHEdiT-"
      },
      "source": [
        "import warnings\n",
        "\n",
        "np.random.seed(23)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlPVjuNdotN"
      },
      "source": [
        "df_baseline = df_Injury_Start\n",
        "\n",
        "#df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True, inplace=True)\n",
        "df_baseline.sort_values(by=['Relinquished']).reset_index(drop=True, inplace=True)\n",
        "# df_baseline['FPTS_pred'] = utils.calculate_FPTS(df_baseline)\n",
        "\n",
        "# # Season average\n",
        "# print(' MAE | ', utils.calculate_MAE(df_baseline['FPTS_pred'], df_baseline['FPTS']))\n",
        "# print('RMSE | ', utils.calculate_RMSE(df_baseline['FPTS_pred'], df_baseline['FPTS']))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZXcuk6XgHIJ",
        "outputId": "cd1ed1ef-ab1e-478d-f1d2-02f700356b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_baseline"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Team</th>\n",
              "      <th>Acquired</th>\n",
              "      <th>Relinquished</th>\n",
              "      <th>Notes</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-10-03</td>\n",
              "      <td>Bulls</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carlos Boozer</td>\n",
              "      <td>fractured bone in right pinky finger (out inde...</td>\n",
              "      <td>2430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-10-06</td>\n",
              "      <td>Pistons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jonas Jerebko</td>\n",
              "      <td>torn right Achilles tendon (out indefinitely)</td>\n",
              "      <td>201973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-10-06</td>\n",
              "      <td>Pistons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Terrico White</td>\n",
              "      <td>broken fifth metatarsal in right foot (out ind...</td>\n",
              "      <td>202358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-10-08</td>\n",
              "      <td>Blazers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jeff Ayres</td>\n",
              "      <td>torn ACL in right knee (out indefinitely)</td>\n",
              "      <td>201965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-10-08</td>\n",
              "      <td>Nets</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Troy Murphy</td>\n",
              "      <td>strained lower back (out indefinitely)</td>\n",
              "      <td>2211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27097</th>\n",
              "      <td>2020-09-22</td>\n",
              "      <td>Celtics</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Romeo Langford</td>\n",
              "      <td>surgery on right wrist (out for season)</td>\n",
              "      <td>1629641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27098</th>\n",
              "      <td>2020-09-23</td>\n",
              "      <td>Heat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gabe Vincent</td>\n",
              "      <td>sore right knee (DTD)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27099</th>\n",
              "      <td>2020-09-30</td>\n",
              "      <td>Heat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bam Adebayo</td>\n",
              "      <td>strained left shoulder (DTD)</td>\n",
              "      <td>1628389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27101</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>Heat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bam Adebayo</td>\n",
              "      <td>strained neck (DTD)</td>\n",
              "      <td>1628389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27102</th>\n",
              "      <td>2020-10-02</td>\n",
              "      <td>Heat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Goran Dragic</td>\n",
              "      <td>placed on IL with torn plantar fascia in left ...</td>\n",
              "      <td>201609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17606 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date  ... PLAYER_ID\n",
              "0      2010-10-03  ...      2430\n",
              "1      2010-10-06  ...    201973\n",
              "2      2010-10-06  ...    202358\n",
              "3      2010-10-08  ...    201965\n",
              "4      2010-10-08  ...      2211\n",
              "...           ...  ...       ...\n",
              "27097  2020-09-22  ...   1629641\n",
              "27098  2020-09-23  ...       NaN\n",
              "27099  2020-09-30  ...   1628389\n",
              "27101  2020-10-02  ...   1628389\n",
              "27102  2020-10-02  ...    201609\n",
              "\n",
              "[17606 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewhp5QtUf7bB"
      },
      "source": [
        "#df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True, inplace=True)\n",
        "df_baseline.sort_values(by=['Relinquished']).reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "# df_baseline['\tPLAYER_ID'] = utils.calculate_FPTS(df_baseline)\n",
        "\n",
        "# # Season average\n",
        "# print(' MAE | ', utils.calculate_MAE(df_baseline['FPTS_pred'], df_baseline['FPTS']))\n",
        "# print('RMSE | ', utils.calculate_RMSE(df_baseline['FPTS_pred'], df_baseline['FPTS']))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5MLXJXId2j1",
        "outputId": "7aecaa0b-725f-427e-fd65-2d12c90a03ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#df_baseline = df_baseline\n",
        "# basic =  ['PTS','3P','AST','TRB','STL','BLK','TOV', 'DD', 'TD']\n",
        "\n",
        "X = df_baseline.PLAYER_ID\n",
        "# X = df_baseline.loc[:, basic]\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "y = df_baseline['FPTS'].values.reshape(-1,1).flatten()\n",
        "\n",
        "reg = LinearRegression()\n",
        "errors = utils.cross_val(reg, X, y, n_folds=5, verbose=0)\n",
        "utils.summarize_errors(errors)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0e1f1283e30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLAYER_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# X = df_baseline.loc[:, basic]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FPTS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         X = check_array(X,\n\u001b[1;32m    372\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[   2430.  201973.  202358. ... 1628389. 1628389.  201609.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXuXIaPzd9Dm"
      },
      "source": [
        "# When the dataframes are combined, use this code to select features.\n",
        "\n",
        "features = ['SG', 'F', 'C', 'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT',\n",
        "            'FTA', 'FGA', '3PA', 'DRB', 'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc',\n",
        "            'ORB_perc', 'BLK_perc', 'TOV_perc', 'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB8L5ZsSeGue",
        "outputId": "11bee0b2-3ea2-4e43-f611-3e52d161a689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "for weighting in ['sqrt', 'linear', 'quad']:\n",
        "    print(\"\\nweighting sheme:\", weighting)\n",
        "    df_features = utils.csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling', 'Features', weighting))  \n",
        "    \n",
        "    X = df_features.loc[:, features]\n",
        "    X = MinMaxScaler().fit_transform(X)\n",
        "    y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
        "\n",
        "    reg = LinearRegression()\n",
        "\n",
        "#Utils isn't working for me. We're going to have to find a new Import (Unless you know what I'm doing wrong with utils)\n",
        "\n",
        "    errors = utils.cross_val(reg, X, y, n_folds=5, verbose=0)\n",
        "    utils.summarize_errors(errors, verbose=0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "weighting sheme: sqrt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-78acd1cf69ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweighting\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nweighting sheme:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataframes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Modelling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'csv_concatenate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RWhlADReKdI",
        "outputId": "7930bcf3-efdb-4722-9101-43c21311beb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "weighting = 'quad'\n",
        "df_features = utils.csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling', 'Features', weighting))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-46212b99e8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweighting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'quad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataframes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Modelling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'csv_concatenate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2IhyvVJeK9m"
      },
      "source": [
        "_all = ['Salary', 'Rest', 'Rota_All', 'Rota_Pos', 'Home', 'SG', 'F', 'C', 'Value', 'FPTS_std',\n",
        "        'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT', 'FTA', 'FGA', '3PA', 'DRB',\n",
        "        'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc', 'ORB_perc', 'BLK_perc', 'TOV_perc', \n",
        "        'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s21vTbJeOWH",
        "outputId": "41027a83-b1d8-43be-ce60-77be175204ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "\n",
        "X = df_features.loc[:, _all]\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
        "\n",
        "# Takes 2 minutes\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "top_features = pd.Series(model.feature_importances_, index = _all).sort_values()\n",
        "top_features.plot(kind = \"barh\", figsize=(15,10) ,title='Top Features')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c4d097cbcb61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FPTS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhzQuuh_eU9O"
      },
      "source": [
        "omit_lowest = 20\n",
        "_selected = list(top_features[omit_lowest:].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbIFz9N0eYQo"
      },
      "source": [
        "for feature_type in [_all, _selected]:\n",
        "    for weighting in ['sqrt', 'linear', 'quad']:\n",
        "        df_features = utils.csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling',\n",
        "                                                         'Features', weighting))\n",
        "        print(\"\\nweighting sheme: {}\".format(weighting))\n",
        "\n",
        "        X = df_features.loc[:, feature_type]\n",
        "        X = MinMaxScaler().fit_transform(X)\n",
        "        y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
        "        \n",
        "        reg = LinearRegression()\n",
        "\n",
        "        errors = utils.cross_val(reg, X, y, verbose=0)\n",
        "        utils.summarize_errors(errors, verbose=0)\n",
        "        \n",
        "    print(\"========================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljY6_iyRdbTN"
      },
      "source": [
        "# DONE ADDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AA48g-jftpp"
      },
      "source": [
        "# Define Sequential model with 3 layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
        "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
        "        layers.Dense(4, name=\"layer3\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "x = df_baseline\n",
        "# x = tf.ones((3, 3))\n",
        "y = model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLGlczbef3pZ"
      },
      "source": [
        "Insert Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQf0RZ8f20Z"
      },
      "source": [
        "# Create 3 layers\n",
        "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
        "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# Call layers on a test input\n",
        "x = df_baseline\n",
        "y = layer3(layer2(layer1(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgrBDgnp_r-W"
      },
      "source": [
        "# Part 3 Conclusions\n",
        "\n",
        "This is where the conclusions section will be typed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne27vROk_r-W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}