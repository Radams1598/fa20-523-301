{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2A5YbSWLX_92"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZS0wkHPlyFO"
      },
      "source": [
        "# Final Project Notebook\n",
        "\n",
        "The report for this final project can be found at this [link](https://cybertraining-dsc.github.io/report/fa20-523-301/project/project/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvjolHp0lvEG"
      },
      "source": [
        "## Part 1 Importing the functions\n",
        "\n",
        "This file requires that we import Numpy, Matplotlib, Pylab, Keras, and Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBEQu5Gpl-eq"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.datasets import make_regression\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36YZ6mkT5iGO",
        "outputId": "b74b4d2b-4f5f-4068-82ea-8076ef6943a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install cloudmesh-common -U\n",
        "\n",
        "from cloudmesh.common.Benchmark import Benchmark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloudmesh-common\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/a8/a01b2ef13709120a47311c17631d80acff89ac6afe01f4f0046ec70668c3/cloudmesh_common-4.3.26-py2.py3-none-any.whl (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2.23.0)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.7MB/s \n",
            "\u001b[?25hCollecting oyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/37/aa/111610d8bf5b1bb7a295a048fc648cec346347a8b0be5881defd2d1b4a52/oyaml-1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: humanize in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (5.4.8)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pathlib in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from cloudmesh-common) (2.8.1)\n",
            "Collecting python-hostlist\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/4f/f31dd4b4bf1a57a5c29599e1165d0df70dbdddcfa59a7c1d04ee2ff4ccbd/python-hostlist-1.21.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cloudmesh-common) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from oyaml->cloudmesh-common) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->cloudmesh-common) (1.15.0)\n",
            "Building wheels for collected packages: python-hostlist\n",
            "  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-hostlist: filename=python_hostlist-1.21-cp36-none-any.whl size=38932 sha256=2707ef8eb9ca52382d60e5f984e9c32585c26f2ad02d6afbc989a52981db6f42\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/5b/55/ddcf52288f0b10f4564ca1b2531594ff7ccc65f487ba8dc437\n",
            "Successfully built python-hostlist\n",
            "Installing collected packages: simplejson, oyaml, colorama, python-hostlist, cloudmesh-common\n",
            "Successfully installed cloudmesh-common-4.3.26 colorama-0.4.4 oyaml-1.0 python-hostlist-1.21 simplejson-3.17.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntN4MMO7i02q",
        "outputId": "9ba39d2f-a7eb-4d1c-8f80-f3a37b8edff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install utils\n",
        "! pip install lightgbm\n",
        "import utils\n",
        "import lightgbm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70n0OaVPemCD",
        "outputId": "34400cc1-0e9a-4dde-e5c0-3380daf6f447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8amMjN4X4Rh"
      },
      "source": [
        "## Conditioned Code. Only Use this for work to save on processing.\n",
        "\n",
        "Moved all of the files to the following [Drive Location](https://drive.google.com/drive/folders/1flPbO7Q0ID70Or_OZ4MdW6CbYDE32GeT). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNaOdpd3X3Gv"
      },
      "source": [
        "########################################################################\n",
        "# Load In Conditioned Datasets - Upload to the Colab files on the left #\n",
        "########################################################################\n",
        "\n",
        "# df_Injury_End\n",
        "df_Injury_End = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/df_Injury_End.csv\")  \n",
        "# df_Injury_length\n",
        "df_Injury_length = pd.read_csv('/content/drive/My Drive/Colab Notebooks/df_Injury_length.csv') \n",
        "# df_Injury_Start\n",
        "df_Injury_Start = pd.read_csv('/content/drive/My Drive/Colab Notebooks/df_Injury_Start.csv') \n",
        "\n",
        "ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "#nba games dataset\n",
        "df_Games_games = pd.read_csv('/content/drive/My Drive/Colab Notebooks/games.csv')\n",
        "df_Games_gamesDetails = pd.read_csv('/content/drive/My Drive/Colab Notebooks/games_details.csv')\n",
        "df_Games_players = pd.read_csv('/content/drive/My Drive/Colab Notebooks/players.csv')\n",
        "df_Games_ranking = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ranking.csv')\n",
        "df_Games_teams = pd.read_csv('/content/drive/My Drive/Colab Notebooks/teams.csv')\n",
        "ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_0mYnzsd73"
      },
      "source": [
        "# ########################################################################\n",
        "# # Load In Conditioned Datasets - Upload to the Colab files on the left #\n",
        "# ########################################################################\n",
        "\n",
        "# # df_Injury_End\n",
        "# df_Injury_End = pd.read_csv(\"df_Injury_End.csv\")  \n",
        "# # df_Injury_length\n",
        "# df_Injury_length = pd.read_csv('df_Injury_length.csv') \n",
        "# # df_Injury_Start\n",
        "# df_Injury_Start = pd.read_csv('df_Injury_Start.csv') \n",
        "\n",
        "# ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "# #nba games dataset\n",
        "# df_Games_games = pd.read_csv('games.csv')\n",
        "# df_Games_gamesDetails = pd.read_csv('games_details.csv')\n",
        "# df_Games_players = pd.read_csv('players.csv')\n",
        "# df_Games_ranking = pd.read_csv('ranking.csv')\n",
        "# df_Games_teams = pd.read_csv('teams.csv')\n",
        "# ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A5YbSWLX_92"
      },
      "source": [
        "## The following is what to use if the data hasn't been conditioned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81DVIg2vo1t"
      },
      "source": [
        "Now that the funtions have been imported the team can focus on the download coding. The following cells will set up an install for Kaggle files and prompt for an upload of the kaggle.json file for credentials. \n",
        "\n",
        "The mkdir function creates a directory for the Kaggle data. This cell will allow the team to verify that the kaggle.json file appropriately uploaded to the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxduR8dEBwvz",
        "outputId": "66c8efd1-6393-4430-be30-71d48d84d40b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "##import the kaggle.json from local to drive\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "##when it asks you to choose a file select the kaggle.json located within the 'project' folder from the github repo\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c05cc82-ee7c-4e5d-a523-d6f2e0a95db6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c05cc82-ee7c-4e5d-a523-d6f2e0a95db6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hemmerleingavin\",\"key\":\"a0412c93ecb33476babdf128d77136c9\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlgk1uL5D0Us",
        "outputId": "6cea4721-4b37-440d-ce97-98450b716996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##make a kaggle and a data folder\n",
        "!mkdir ~/.kaggle\n",
        "!mkdir data\n",
        "##copy the kaggle.json to the .kaggle folder then grant permissions\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#test to see if kaggle is working, should print list of datasets\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "ref                                                       title                                         size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------------  -------------------------------------------  -----  -------------------  -------------  \n",
            "manchunhui/us-election-2020-tweets                        US Election 2020 Tweets                      276MB  2020-11-07 12:06:54            612  \n",
            "unanimad/us-election-2020                                 US Election 2020                             418KB  2020-11-07 19:43:37            432  \n",
            "headsortails/us-election-2020-presidential-debates        US Election 2020 - Presidential Debates      199MB  2020-10-23 16:56:10            222  \n",
            "radustoicescu/2020-united-states-presidential-election    2020 United States presidential election      11MB  2019-07-04 15:00:45            549  \n",
            "etsc9287/2020-general-election-polls                      2020 General Election Polls                  109KB  2020-02-09 08:20:59            326  \n",
            "shivamb/netflix-shows                                     Netflix Movies and TV Shows                  971KB  2020-01-20 07:33:56          55063  \n",
            "terenceshin/covid19s-impact-on-airport-traffic            COVID-19's Impact on Airport Traffic         106KB  2020-10-19 12:40:17           2842  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019     Amazon Top 50 Bestselling Books 2009 - 2019   15KB  2020-10-13 09:39:21           2775  \n",
            "nehaprabhavalkar/indian-food-101                          Indian Food 101                                7KB  2020-09-30 06:23:43           6406  \n",
            "omarhanyy/500-greatest-songs-of-all-time                  500 Greatest Songs of All Time                33KB  2020-10-26 13:36:09            857  \n",
            "heeraldedhia/groceries-dataset                            Groceries dataset                            257KB  2020-09-17 04:36:08           6787  \n",
            "andrewmvd/trip-advisor-hotel-reviews                      Trip Advisor Hotel Reviews                     5MB  2020-09-30 08:31:20           4555  \n",
            "karangadiya/fifa19                                        FIFA 19 complete player dataset                2MB  2018-12-21 03:52:59         102578  \n",
            "docstein/brics-world-bank-indicators                      BRICS World Bank Indicators                    4MB  2020-10-22 12:18:40            695  \n",
            "thomaskonstantin/highly-rated-children-books-and-stories  Highly Rated Children Books And Stories      106KB  2020-10-24 12:09:59            526  \n",
            "christianlillelund/donald-trumps-rallies                  Donald Trump's Rallies                       720KB  2020-09-26 10:25:08           1565  \n",
            "datasnaek/youtube-new                                     Trending YouTube Video Statistics            201MB  2019-06-03 00:56:47         113761  \n",
            "google/tinyquickdraw                                      QuickDraw Sketches                            11GB  2018-04-18 19:38:04           2425  \n",
            "anikannal/solar-power-generation-data                     Solar Power Generation Data                    2MB  2020-08-18 15:52:03           9091  \n",
            "zynicide/wine-reviews                                     Wine Reviews                                  51MB  2017-11-27 17:08:04         117886  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKEX-7tbwMK-"
      },
      "source": [
        "Now, the team must download all of the datasets for the class. The three datasets are focused on the NBA. \n",
        "\n",
        "The first dataset is for injuries. Each injury will be used to set up players, timeframes, and severity of injuries. \n",
        "\n",
        "The other two datasets are for the player performance. By cross referencing this data to the previous list, the team will be able to see which players are limited from the injury and how performance is hampered by time in rehab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2QYBlpIEFBi",
        "outputId": "4881a239-b8d0-44ec-ac43-2b5cc462be2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##downloading all the datasets\n",
        "!kaggle datasets download -d ghopkins/nba-injuries-2010-2018\n",
        "!kaggle datasets download -d nathanlauga/nba-games\n",
        "!kaggle datasets download -d pablote/nba-enhanced-stats\n",
        "##unzipping to the data folder\n",
        "!unzip nba-injuries-2010-2018.zip -d data\n",
        "!unzip nba-games.zip -d data\n",
        "!unzip nba-enhanced-stats.zip -d data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading nba-injuries-2010-2018.zip to /content\n",
            "\r  0% 0.00/226k [00:00<?, ?B/s]\n",
            "100% 226k/226k [00:00<00:00, 86.8MB/s]\n",
            "Downloading nba-games.zip to /content\n",
            " 99% 18.0M/18.1M [00:01<00:00, 7.04MB/s]\n",
            "100% 18.1M/18.1M [00:01<00:00, 10.7MB/s]\n",
            "Downloading nba-enhanced-stats.zip to /content\n",
            " 54% 9.00M/16.7M [00:01<00:01, 6.99MB/s]\n",
            "100% 16.7M/16.7M [00:01<00:00, 10.5MB/s]\n",
            "Archive:  nba-injuries-2010-2018.zip\n",
            "  inflating: data/injuries_2010-2020.csv  \n",
            "Archive:  nba-games.zip\n",
            "  inflating: data/games.csv          \n",
            "  inflating: data/games_details.csv  \n",
            "  inflating: data/players.csv        \n",
            "  inflating: data/ranking.csv        \n",
            "  inflating: data/teams.csv          \n",
            "Archive:  nba-enhanced-stats.zip\n",
            "  inflating: data/2012-18_officialBoxScore.csv  \n",
            "  inflating: data/2012-18_playerBoxScore.csv  \n",
            "  inflating: data/2012-18_standings.csv  \n",
            "  inflating: data/2012-18_teamBoxScore.csv  \n",
            "  inflating: data/2016-17_officialBoxScore.csv  \n",
            "  inflating: data/2016-17_playerBoxScore.csv  \n",
            "  inflating: data/2016-17_standings.csv  \n",
            "  inflating: data/2016-17_teamBoxScore.csv  \n",
            "  inflating: data/2017-18_officialBoxScore.csv  \n",
            "  inflating: data/2017-18_playerBoxScore.csv  \n",
            "  inflating: data/2017-18_standings.csv  \n",
            "  inflating: data/2017-18_teamBoxScore.csv  \n",
            "  inflating: data/metadata_officialBoxScore.pdf  \n",
            "  inflating: data/metadata_playerBoxScore.pdf  \n",
            "  inflating: data/metadata_standing.pdf  \n",
            "  inflating: data/metadata_teamBoxScore.pdf  \n",
            "  inflating: data/teamBoxScore.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5s1uc4Q4msJ"
      },
      "source": [
        "########################################################################\n",
        "# Load In Conditioned Datasets - Upload to the Colab files on the left #\n",
        "########################################################################\n",
        "\n",
        "# df_Injury_End\n",
        "df_Injury_End = pd.read_csv(\"df_Injury_End.csv\")  \n",
        "# df_Injury_length\n",
        "df_Injury_length = pd.read_csv('df_Injury_length.csv') \n",
        "# df_Injury_Start\n",
        "df_Injury_Start = pd.read_csv('df_Injury_Start.csv') \n",
        "\n",
        "ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "#nba games dataset\n",
        "df_Games_games = pd.read_csv('games.csv')\n",
        "df_Games_gamesDetails = pd.read_csv('games_details.csv')\n",
        "df_Games_players = pd.read_csv('players.csv')\n",
        "df_Games_ranking = pd.read_csv('ranking.csv')\n",
        "df_Games_teams = pd.read_csv('teams.csv')\n",
        "ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ipj2A1YIZR"
      },
      "source": [
        "## We are now ready to structure our dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aIzY8a4wusX"
      },
      "source": [
        "The team must now use these downloads to create dataframes. Pandas dataframes will be easier to manage the data. The team will be able to use Pandas to process the data and allow the team to make correlations for feature engineering to create the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zmpmw-zImsz",
        "outputId": "885ec719-8eca-4a98-a412-58d105fa8368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "# ############################################################\n",
        "# # Do not run until final run. Use the conditioned datasets #\n",
        "# ############################################################\n",
        "\n",
        "\n",
        "# #create a list for each data set\n",
        "# ds_NBA_Injuries, ds_NBA_Games, ds_NBA_Enhanced = [], [], []\n",
        "\n",
        "# #import csv files as dataframes and save to respective list, injury set first\n",
        "\n",
        "# df_Injuries = pd.read_csv('data/injuries_2010-2020.csv')\n",
        "# df_Injury_Start = df_Injuries[df_Injuries.Acquired.isnull()]\n",
        "# df_Injury_End = df_Injuries[df_Injuries.Relinquished.isnull()]\n",
        "\n",
        "# ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "# #nba games dataset\n",
        "# df_Games_games = pd.read_csv('data/games.csv')\n",
        "# df_Games_gamesDetails = pd.read_csv('data/games_details.csv')\n",
        "# df_Games_players = pd.read_csv('data/players.csv')\n",
        "# df_Games_ranking = pd.read_csv('data/ranking.csv')\n",
        "# df_Games_teams = pd.read_csv('data/teams.csv')\n",
        "# ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]\n",
        "# #nba enhanced stats dataset\n",
        "# #df_En_officialBS_1218 = pd.read_csv('data/2012-18_officialBoxScore.csv')\n",
        "# #df_En_playerBS_1218 = pd.read_csv('data/2012-18_playerBoxScore.csv')\n",
        "# #df_En_standings_1218 = pd.read_csv('data/2012-18_standings.csv')\n",
        "# #df_En_teamBS_1218 = pd.read_csv('data/2012-18_teamBoxScore.csv')  \n",
        "# #df_En_officialBS_1617 = pd.read_csv('data/2016-17_officialBoxScore.csv')  \n",
        "# #df_En_playerBS_1617 = pd.read_csv('data/2016-17_playerBoxScore.csv')\n",
        "# #df_En_standings_1617 = pd.read_csv('data/2016-17_standings.csv')\n",
        "# #df_En_teamBS_1617 = pd.read_csv('data/2016-17_teamBoxScore.csv')  \n",
        "# #df_En_officialBS_1718 = pd.read_csv('data/2017-18_officialBoxScore.csv')  \n",
        "# #df_En_playerBS_1718 = pd.read_csv('data/2017-18_playerBoxScore.csv')\n",
        "# #df_En_standings_1718 = pd.read_csv('data/2017-18_standings.csv')\n",
        "# #df_En_teamBS_1718 = pd.read_csv('data/2017-18_teamBoxScore.csv')  \n",
        "# ##data/metadata_officialBoxScore.pdf, data/metadata_playerBoxScore.pdf, data/metadata_standing.pdf, data/metadata_teamBoxScore.pdf  \n",
        "# #df_En_teamBS = pd.read_csv('data/teamBoxScore.csv')\n",
        "# #ds_NBA_Enhanced = [df_En_officialBS_1218, df_En_officialBS_1617, df_En_officialBS_1718, df_En_playerBS_1218, df_En_playerBS_1617, df_En_playerBS_1718, df_En_standings_1218, df_En_standings_1617, df_En_standings_1718, \\\n",
        "# #                       df_En_teamBS_1218, df_En_teamBS_1617, df_En_teamBS_1718, df_En_teamBS]\n",
        "\n",
        "\n",
        "# #probably need some more data exploration and some feature engineering"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0b1c29f25eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#import csv files as dataframes and save to respective list, injury set first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_Injuries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/injuries_2010-2020.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injuries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_Injuries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcquired\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf_Injury_End\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injuries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_Injuries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelinquished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/injuries_2010-2020.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCknO5JCK-o"
      },
      "source": [
        "###Feature Engineering for Injury sets\n",
        "#####Goal is to have stats for injury game, average stats of last/first 5 games and maybe join season avg?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CviX4Qh0ASgW",
        "outputId": "c1463316-37b6-44ba-d3ab-4f12bdcd7568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "############################################################\n",
        "# Do not run until final run. Use the conditioned datasets #\n",
        "############################################################\n",
        "\n",
        "\n",
        "#distinct player and player ID list\n",
        "df_distinct_playerID = df_Games_players[[\"PLAYER_NAME\", \"PLAYER_ID\"]].drop_duplicates()\n",
        "df_distinct_playerID.astype({'PLAYER_ID':'object'}).dtypes\n",
        "#distinct gameID and game date list\n",
        "df_Games_games['GAME_DATE_EST'] = pd.to_datetime(df_Games_games['GAME_DATE_EST'])\n",
        "df_distinct_gameId_date = df_Games_games[[\"GAME_ID\", \"GAME_DATE_EST\"]].drop_duplicates()\n",
        "#join player ID, for j=injury start db\n",
        "df_Injury_Start = df_Injury_Start.join(df_distinct_playerID.astype('object').set_index('PLAYER_NAME'), on='Relinquished')\n",
        "df_Injury_Start = df_Injury_Start.merge(df_Games_teams[[\"TEAM_ID\", \"NICKNAME\"]], left_on=\"Team\", right_on=\"NICKNAME\")\n",
        "df_Injury_Start = df_Injury_Start.drop(['NICKNAME'], axis=1)\n",
        "df_Injury_Start['Date']= pd.to_datetime(df_Injury_Start['Date'])#.apply(lambda x: x.date())\n",
        "#again for injury end db\n",
        "df_Injury_End = df_Injury_End.join(df_distinct_playerID.astype('object').set_index('PLAYER_NAME'), on='Acquired')\n",
        "df_Injury_End = df_Injury_End.merge(df_Games_teams[[\"TEAM_ID\", \"NICKNAME\"]], left_on=\"Team\", right_on=\"NICKNAME\")\n",
        "df_Injury_End = df_Injury_End.drop(['NICKNAME'], axis=1)\n",
        "df_Injury_End['Date']= pd.to_datetime(df_Injury_End['Date'])#.apply(lambda x: x.date())\n",
        "# df_distinct_playerID=df_distinct_playerID.sort_values('PLAYER_NAME')\n",
        "df_Games_gamesDetails = df_Games_gamesDetails.merge(df_distinct_gameId_date, on=\"GAME_ID\")\n",
        "\n",
        "# df_distinct_playerID = df_distinct_playerID.sort_values(by=['PLAYER_NAME']).reset_index(drop=True, inplace=True)\n",
        "#df_Injury_End"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6494468c1d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_distinct_gameId_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Games_games\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAME_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GAME_DATE_EST\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#join player ID, for j=injury start db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_Injury_Start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_distinct_playerID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PLAYER_NAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Relinquished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Games_teams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TEAM_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NICKNAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Team\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NICKNAME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NICKNAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7873\u001b[0m         \"\"\"\n\u001b[1;32m   7874\u001b[0m         return self._join_compat(\n\u001b[0;32m-> 7875\u001b[0;31m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7876\u001b[0m         )\n\u001b[1;32m   7877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7896\u001b[0m                 \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7897\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7898\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7899\u001b[0m             )\n\u001b[1;32m   7900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         )\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['PLAYER_ID'], dtype='object')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFpaEfk4w_DG"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "At this point, it is time to build into new useful sets of data. The team will explore different sets to combine in to the models to be trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrtNcltKkVUC"
      },
      "source": [
        "### **To be deleted later**\n",
        "This code is put in to make the dataset much smaller. The datasets will normally be done on the larger set, but for buildup we want to use a smaller subset so the training does not take hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53OfEv6ihDVU",
        "outputId": "178018b2-d8f2-451e-c816-d40f6d1f7668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "### GH_Add ## Slicing Rows to make it easier to build up program\n",
        "df_Games_gamesDetails_orig = df_Games_gamesDetails.copy()\n",
        "df_Games_gamesDetails = df_Games_gamesDetails[0:201].copy()\n",
        "\n",
        "df_Injury_Start_orig = df_Injury_Start.copy()\n",
        "df_Injury_Start = df_Injury_Start[0:201].copy()\n",
        "\n",
        "df_Injury_End_orig = df_Injury_End.copy()\n",
        "df_Injury_End = df_Injury_End[0:201].copy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f51d01234553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### GH_Add ## Slicing Rows to make it easier to build up program\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_Games_gamesDetails_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_Games_gamesDetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_Injury_Start_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_Games_gamesDetails' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGAu05JixyFQ",
        "outputId": "2221c96a-cc9a-4264-d70f-7dbb11919855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "\n",
        "for index, row in df_Games_gamesDetails.iterrows():\n",
        "  try:\n",
        "    m, s = str(row.MIN).split(':')\n",
        "  except (SyntaxError, ValueError) as e:\n",
        "    m = (row.MIN)\n",
        "    s = 0\n",
        "  df_Games_gamesDetails.loc[index,'MIN'] = pd.to_numeric(m) + pd.to_numeric(s)/60\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a0d8e1e6591d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MIN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0minfo_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minfo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;31m# Ensure we have something we can iterate over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rI2ZY9PDGIv",
        "outputId": "61a85ecb-cc2a-4f39-ff15-e4ab1ab4ba5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for index, row in df_Injury_Start.iterrows():\n",
        "        #games of just that player\n",
        "        temp = df_Games_gamesDetails.loc[df_Games_gamesDetails['PLAYER_ID'] == row.PLAYER_ID]\n",
        "        #games before and inlucding injury date\n",
        "        inj_game = temp.loc[(temp['GAME_DATE_EST'] == row.Date)]\n",
        "        #5 games prior and the game of injury, for some reason we need to have 4 different variabels, did not work with resetting the variable 'game_set' to itself\n",
        "        temp2 = temp.loc[(temp['GAME_DATE_EST'] <= row.Date)]\n",
        "        game_set = temp2.nlargest(6, 'GAME_DATE_EST')\n",
        "        if len(game_set) > 0:\n",
        "          #injury game\n",
        "          inj_game = game_set.iloc[0]\n",
        "          #5 games prior to injury\n",
        "          prior5 = game_set.iloc[1:]\n",
        "          #storing game data from injury game\n",
        "          df_Injury_Start.at[index, 'inj_MIN'] = inj_game[['MIN']].MIN\n",
        "          df_Injury_Start.at[index,'inj_FGA'] = inj_game[['FGA']].FGA\n",
        "          df_Injury_Start.at[index,'inj_FG_PCT'] = inj_game[['FG_PCT']].FG_PCT\n",
        "          df_Injury_Start.at[index,'inj_FG3A'] = inj_game[['FG3A']].FG3A\n",
        "          df_Injury_Start.at[index,'inj_FG3_PCT'] = inj_game[['FG3_PCT']].FG3_PCT\n",
        "          df_Injury_Start.loc[index,'inj_FTA'] = inj_game[['FTA']].FTA\n",
        "          df_Injury_Start.loc[index,'inj_FT_PCT'] = inj_game[['FT_PCT']].FT_PCT\n",
        "          df_Injury_Start.loc[index,'inj_REB'] = inj_game[['REB']].REB\n",
        "          df_Injury_Start.loc[index,'inj_AST'] = inj_game[['AST']].AST\n",
        "          df_Injury_Start.loc[index,'inj_STL'] = inj_game[['STL']].STL\n",
        "          df_Injury_Start.loc[index,'inj_BLK'] = inj_game[['BLK']].BLK\n",
        "          df_Injury_Start.loc[index,'inj_TO'] = inj_game[['TO']].TO\n",
        "          df_Injury_Start.loc[index,'inj_PF'] = inj_game[['PF']].PF\n",
        "          df_Injury_Start.loc[index,'inj_PTS'] = inj_game[['PTS']].PTS\n",
        "          df_Injury_Start.loc[index,'inj_PLUS_MINUS'] = inj_game[['PLUS_MINUS']].PLUS_MINUS\n",
        "#storing game data from prior 5 games\n",
        "          df_Injury_Start.at[index,'p5_MIN'] = prior5[['MIN']].MIN.mean()\n",
        "          df_Injury_Start.at[index,'p5_FGA'] = prior5[['FGA']].FGA.mean()\n",
        "          df_Injury_Start.at[index,'p5_FG_PCT'] = prior5[['FG_PCT']].FG_PCT.mean()\n",
        "          df_Injury_Start.at[index,'p5_FG3A'] = prior5[['FG3A']].FG3A.mean()\n",
        "          df_Injury_Start.at[index,'p5_FG3_PCT'] = prior5[['FG3_PCT']].FG3_PCT.mean()\n",
        "          df_Injury_Start.at[index,'p5_FTA'] = prior5[['FTA']].FTA.mean()\n",
        "          df_Injury_Start.at[index,'p5_FT_PCT'] = prior5[['FT_PCT']].FT_PCT.mean()\n",
        "          df_Injury_Start.at[index,'p5_REB'] = prior5[['REB']].REB.mean()\n",
        "          df_Injury_Start.at[index,'p5_AST'] = prior5[['AST']].AST.mean()\n",
        "          df_Injury_Start.at[index,'p5_STL'] = prior5[['STL']].STL.mean()\n",
        "          df_Injury_Start.at[index,'p5_BLK'] = prior5[['BLK']].BLK.mean()\n",
        "          df_Injury_Start.at[index,'p5_TO'] = prior5[['TO']].TO.mean()\n",
        "          df_Injury_Start.at[index,'p5_PF'] = prior5[['PF']].PF.mean()\n",
        "          df_Injury_Start.at[index,'p5_PTS'] = prior5[['PTS']].PTS.mean()\n",
        "          df_Injury_Start.at[index,'p5_PLUS_MINUS'] = prior5[['PLUS_MINUS']].PLUS_MINUS.mean()\n",
        "          \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fc288ee6d7a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_Injury_Start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;31m#games of just that player\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLAYER_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m#games before and inlucding injury date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minj_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GAME_DATE_EST'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_Games_gamesDetails' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udzmFjS-ivuC",
        "outputId": "099e3560-eb5e-4777-8d6a-bfab9732863a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "#df_Injury_End\n",
        "for index, row in df_Injury_End.iterrows():\n",
        "        #games of just that player\n",
        "        temp = df_Games_gamesDetails.loc[df_Games_gamesDetails['PLAYER_ID'] == row.PLAYER_ID]\n",
        "        #games before and inlucding injury date\n",
        "        temp2 = temp.loc[(temp['GAME_DATE_EST'] >= row.Date)]\n",
        "        #5 games prior and the game of injury, for some reason we need to have 4 different variabels, did not work with resetting the variable 'game_set' to itself\n",
        "        game_set = temp.nsmallest(6, 'GAME_DATE_EST')\n",
        "        if len(game_set) > 0:\n",
        "          #injury game\n",
        "          inj_game = game_set.iloc[0]\n",
        "          #5 games post injury\n",
        "          post5 = game_set.iloc[1:]\n",
        "          #storing game data from injury game\n",
        "          df_Injury_End.at[index, 'inj_MIN'] = inj_game[['MIN']].MIN\n",
        "          df_Injury_End.at[index,'inj_FGA'] = inj_game[['FGA']].FGA\n",
        "          df_Injury_End.at[index,'inj_FG_PCT'] = inj_game[['FG_PCT']].FG_PCT\n",
        "          df_Injury_End.at[index,'inj_FG3A'] = inj_game[['FG3A']].FG3A\n",
        "          df_Injury_End.at[index,'inj_FG3_PCT'] = inj_game[['FG3_PCT']].FG3_PCT\n",
        "          df_Injury_End.loc[index,'inj_FTA'] = inj_game[['FTA']].FTA\n",
        "          df_Injury_End.loc[index,'inj_FT_PCT'] = inj_game[['FT_PCT']].FT_PCT\n",
        "          df_Injury_End.loc[index,'inj_REB'] = inj_game[['REB']].REB\n",
        "          df_Injury_End.loc[index,'inj_AST'] = inj_game[['AST']].AST\n",
        "          df_Injury_End.loc[index,'inj_STL'] = inj_game[['STL']].STL\n",
        "          df_Injury_End.loc[index,'inj_BLK'] = inj_game[['BLK']].BLK\n",
        "          df_Injury_End.loc[index,'inj_TO'] = inj_game[['TO']].TO\n",
        "          df_Injury_End.loc[index,'inj_PF'] = inj_game[['PF']].PF\n",
        "          df_Injury_End.loc[index,'inj_PTS'] = inj_game[['PTS']].PTS\n",
        "          df_Injury_End.loc[index,'inj_PLUS_MINUS'] = inj_game[['PLUS_MINUS']].PLUS_MINUS\n",
        "          #storing game data from prior 5 games\n",
        "          df_Injury_End.at[index,'p5_MIN'] = post5[['MIN']].MIN.mean()\n",
        "          df_Injury_End.at[index,'p5_FGA'] = post5[['FGA']].FGA.mean()\n",
        "          df_Injury_End.at[index,'p5_FG_PCT'] = post5[['FG_PCT']].FG_PCT.mean()\n",
        "          df_Injury_End.at[index,'p5_FG3A'] = post5[['FG3A']].FG3A.mean()\n",
        "          df_Injury_End.at[index,'p5_FG3_PCT'] = post5[['FG3_PCT']].FG3_PCT.mean()\n",
        "          df_Injury_End.at[index,'p5_FTA'] = post5[['FTA']].FTA.mean()\n",
        "          df_Injury_End.at[index,'p5_FT_PCT'] = post5[['FT_PCT']].FT_PCT.mean()\n",
        "          df_Injury_End.at[index,'p5_REB'] = post5[['REB']].REB.mean()\n",
        "          df_Injury_End.at[index,'p5_AST'] = post5[['AST']].AST.mean()\n",
        "          df_Injury_End.at[index,'p5_STL'] = post5[['STL']].STL.mean()\n",
        "          df_Injury_End.at[index,'p5_BLK'] = post5[['BLK']].BLK.mean()\n",
        "          df_Injury_End.at[index,'p5_TO'] = post5[['TO']].TO.mean()\n",
        "          df_Injury_End.at[index,'p5_PF'] = post5[['PF']].PF.mean()\n",
        "          df_Injury_End.at[index,'p5_PTS'] = post5[['PTS']].PTS.mean()\n",
        "          df_Injury_End.at[index,'p5_PLUS_MINUS'] = post5[['PLUS_MINUS']].PLUS_MINUS.mean()\n",
        "        #print(inj_game)\n",
        "\n",
        "        #print(inj_game)\n",
        "        #print(prior5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GAME_DATE_EST'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-40cf0a40ca25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_Games_gamesDetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAYER_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLAYER_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#games before and inlucding injury date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GAME_DATE_EST'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#5 games prior and the game of injury, for some reason we need to have 4 different variabels, did not work with resetting the variable 'game_set' to itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgame_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GAME_DATE_EST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GAME_DATE_EST'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNgn64ED-L8X"
      },
      "source": [
        "## Adding\n",
        "Starting to build up injury performance for model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOnCFzEe-Tt8",
        "outputId": "9c489113-4955-476b-efd7-62eb8c3191de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "prior5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d630eef2f218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprior5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prior5' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLp742E5ftIr"
      },
      "source": [
        "# Part 2 Building the Models\n",
        "\n",
        "A link for Keras for us to use can be found [here](https://keras.io/guides/sequential_model/). We are first going to set up our Benchmark Test to be used when we are Benchmarking our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnUZ7nOe41w_"
      },
      "source": [
        "def b():\n",
        "  Benchmark.Start()\n",
        "  print (\"b\")\n",
        "  import time\n",
        "  time.sleep(3)\n",
        "  Benchmark.Stop()\n",
        "\n",
        "def c():\n",
        "  Benchmark.Start()\n",
        "  print (\"c\")\n",
        "  import time\n",
        "  time.sleep(1)\n",
        "  Benchmark.Stop()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c637S5T65JYz",
        "outputId": "28f7fcb5-a003-4890-8fa4-0dc17450c805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " b()\n",
        " c()\n",
        "\n",
        " Benchmark.print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\n",
            "c\n",
            "\n",
            "+---------------------+------------------------------------------------------------------+\n",
            "| Attribute           | Value                                                            |\n",
            "|---------------------+------------------------------------------------------------------|\n",
            "| BUG_REPORT_URL      | \"https://bugs.launchpad.net/ubuntu/\"                             |\n",
            "| DISTRIB_CODENAME    | bionic                                                           |\n",
            "| DISTRIB_DESCRIPTION | \"Ubuntu 18.04.5 LTS\"                                             |\n",
            "| DISTRIB_ID          | Ubuntu                                                           |\n",
            "| DISTRIB_RELEASE     | 18.04                                                            |\n",
            "| HOME_URL            | \"https://www.ubuntu.com/\"                                        |\n",
            "| ID                  | ubuntu                                                           |\n",
            "| ID_LIKE             | debian                                                           |\n",
            "| NAME                | \"Ubuntu\"                                                         |\n",
            "| PRETTY_NAME         | \"Ubuntu 18.04.5 LTS\"                                             |\n",
            "| PRIVACY_POLICY_URL  | \"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" |\n",
            "| SUPPORT_URL         | \"https://help.ubuntu.com/\"                                       |\n",
            "| UBUNTU_CODENAME     | bionic                                                           |\n",
            "| VERSION             | \"18.04.5 LTS (Bionic Beaver)\"                                    |\n",
            "| VERSION_CODENAME    | bionic                                                           |\n",
            "| VERSION_ID          | \"18.04\"                                                          |\n",
            "| cpu_count           | 2                                                                |\n",
            "| mem.active          | 927.1 MiB                                                        |\n",
            "| mem.available       | 11.7 GiB                                                         |\n",
            "| mem.free            | 9.4 GiB                                                          |\n",
            "| mem.inactive        | 2.1 GiB                                                          |\n",
            "| mem.percent         | 8.3 %                                                            |\n",
            "| mem.total           | 12.7 GiB                                                         |\n",
            "| mem.used            | 1.0 GiB                                                          |\n",
            "| platform.version    | #1 SMP Thu Jul 23 08:00:38 PDT 2020                              |\n",
            "| python              | 3.6.9 (default, Oct  8 2020, 12:12:24)                           |\n",
            "|                     | [GCC 8.4.0]                                                      |\n",
            "| python.pip          | 19.3.1                                                           |\n",
            "| python.version      | 3.6.9                                                            |\n",
            "| sys.platform        | linux                                                            |\n",
            "| uname.machine       | x86_64                                                           |\n",
            "| uname.node          | 3754ed0f0ab5                                                     |\n",
            "| uname.processor     | x86_64                                                           |\n",
            "| uname.release       | 4.19.112+                                                        |\n",
            "| uname.system        | Linux                                                            |\n",
            "| uname.version       | #1 SMP Thu Jul 23 08:00:38 PDT 2020                              |\n",
            "| user                | collab                                                           |\n",
            "+---------------------+------------------------------------------------------------------+\n",
            "\n",
            "+----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------+\n",
            "| Name                             | Status   |   Time |   Sum | Start               | tag   | Node         | User   | OS    | Version                             |\n",
            "|----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------|\n",
            "| <ipython-input-6-124396bcabb3>/b | ok       |  3.031 | 3.031 | 2020-11-07 23:43:24 |       | 3754ed0f0ab5 | collab | Linux | #1 SMP Thu Jul 23 08:00:38 PDT 2020 |\n",
            "| <ipython-input-6-124396bcabb3>/c | ok       |  1.032 | 1.032 | 2020-11-07 23:43:27 |       | 3754ed0f0ab5 | collab | Linux | #1 SMP Thu Jul 23 08:00:38 PDT 2020 |\n",
            "+----------------------------------+----------+--------+-------+---------------------+-------+--------------+--------+-------+-------------------------------------+\n",
            "\n",
            "# csv,timer,status,time,sum,start,tag,uname.node,user,uname.system,platform.version\n",
            "# csv,<ipython-input-6-124396bcabb3>/b,ok,3.031,3.031,2020-11-07 23:43:24,,3754ed0f0ab5,collab,Linux,#1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "# csv,<ipython-input-6-124396bcabb3>/c,ok,1.032,1.032,2020-11-07 23:43:27,,3754ed0f0ab5,collab,Linux,#1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wmn5BA8MGQ"
      },
      "source": [
        "Now that we know which GPU we are using, we can get into the actual work. The following is building our Keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-TMhHEdiT-"
      },
      "source": [
        "np.random.seed(23)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlPVjuNdotN"
      },
      "source": [
        "df_baseline = df_Injury_End\n",
        "sort_by = 'Acquired'\n",
        "\n",
        "#df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True, inplace=True)\n",
        "df_baseline.sort_values(by=[sort_by]).reset_index(drop=True, inplace=True)\n",
        "# df_baseline['FPTS_pred'] = utils.calculate_FPTS(df_baseline)\n",
        "\n",
        "# # Season average\n",
        "# print(' MAE | ', utils.calculate_MAE(df_baseline['FPTS_pred'], df_baseline['FPTS']))\n",
        "# print('RMSE | ', utils.calculate_RMSE(df_baseline['FPTS_pred'], df_baseline['FPTS']))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZXcuk6XgHIJ",
        "outputId": "82d6fc0a-32e9-43b5-8882-7f36d7a1f7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_baseline.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Team</th>\n",
              "      <th>Acquired</th>\n",
              "      <th>Relinquished</th>\n",
              "      <th>Notes</th>\n",
              "      <th>PLAYER_ID</th>\n",
              "      <th>TEAM_ID</th>\n",
              "      <th>NICKNAME</th>\n",
              "      <th>inj_MIN</th>\n",
              "      <th>inj_FGA</th>\n",
              "      <th>inj_FG_PCT</th>\n",
              "      <th>inj_FG3A</th>\n",
              "      <th>inj_FG3_PCT</th>\n",
              "      <th>inj_FTA</th>\n",
              "      <th>inj_FT_PCT</th>\n",
              "      <th>inj_REB</th>\n",
              "      <th>inj_AST</th>\n",
              "      <th>inj_STL</th>\n",
              "      <th>inj_BLK</th>\n",
              "      <th>inj_TO</th>\n",
              "      <th>inj_PF</th>\n",
              "      <th>inj_PTS</th>\n",
              "      <th>inj_PLUS_MINUS</th>\n",
              "      <th>p5_MIN</th>\n",
              "      <th>p5_FGA</th>\n",
              "      <th>p5_FG_PCT</th>\n",
              "      <th>p5_FG3A</th>\n",
              "      <th>p5_FG3_PCT</th>\n",
              "      <th>p5_FTA</th>\n",
              "      <th>p5_FT_PCT</th>\n",
              "      <th>p5_REB</th>\n",
              "      <th>p5_AST</th>\n",
              "      <th>p5_STL</th>\n",
              "      <th>p5_BLK</th>\n",
              "      <th>p5_TO</th>\n",
              "      <th>p5_PF</th>\n",
              "      <th>p5_PTS</th>\n",
              "      <th>p5_PLUS_MINUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Unnamed: 0, Date, Team, Acquired, Relinquished, Notes, PLAYER_ID, TEAM_ID, NICKNAME, inj_MIN, inj_FGA, inj_FG_PCT, inj_FG3A, inj_FG3_PCT, inj_FTA, inj_FT_PCT, inj_REB, inj_AST, inj_STL, inj_BLK, inj_TO, inj_PF, inj_PTS, inj_PLUS_MINUS, p5_MIN, p5_FGA, p5_FG_PCT, p5_FG3A, p5_FG3_PCT, p5_FTA, p5_FT_PCT, p5_REB, p5_AST, p5_STL, p5_BLK, p5_TO, p5_PF, p5_PTS, p5_PLUS_MINUS]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewhp5QtUf7bB"
      },
      "source": [
        "#df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True, inplace=True)\n",
        "df_baseline.sort_values(by=[sort_by]).reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "# df_baseline['\tPLAYER_ID'] = utils.calculate_FPTS(df_baseline)\n",
        "\n",
        "# # Season average\n",
        "# print(' MAE | ', utils.calculate_MAE(df_baseline['FPTS_pred'], df_baseline['FPTS']))\n",
        "# print('RMSE | ', utils.calculate_RMSE(df_baseline['FPTS_pred'], df_baseline['FPTS']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zucYExMnJYbm"
      },
      "source": [
        "# Part No X. Building the Model\n",
        "\n",
        "The team is now moving on to building the model for the baseline. Linear Regression can be used to model the values. Additionally, a Random Forest modeling function was used to verify model performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34VDFf8WJWut"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb-NC9l9KPaF"
      },
      "source": [
        "The pipeline will be built off of using df_baseline.PLAYER_ID. To change the data going into the model, the team had to modify the dataframe input to get to the results. Comments were put around to make it easy to find the code in the Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5MLXJXId2j1"
      },
      "source": [
        "#df_baseline = df_baseline\n",
        "# basic =  ['PTS','3P','AST','TRB','STL','BLK','TOV', 'DD', 'TD']\n",
        "\n",
        "###################################\n",
        "##                               ##\n",
        "##     INSERT CODE               ##\n",
        "##                               ##\n",
        "##     Change DF before here     ##\n",
        "##                               ##\n",
        "##                               ##\n",
        "##                               ##\n",
        "###################################\n",
        "\n",
        "X = df_baseline.p5_PLUS_MINUS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdAiOOwBLLW8",
        "outputId": "b8d1dd46-6e21-44c0-83ec-fd2d82d03d7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = X.values.reshape(-1, 1)\n",
        "# X = X.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# X = df_baseline.loc[:, basic]\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "print(X.shape)\n",
        "# Y = df_baseline['FPTS'].values.reshape(-1,1).flatten()\n",
        "Y = df_baseline.values.reshape(-1,1).flatten() # Y is 38 times larger. Not sure what I did here. \n",
        "Y = Y.reshape(-1, 1) \n",
        "\n",
        "size_x = X.shape[0]\n",
        "size_y = Y.shape[0]\n",
        "size_y = int(size_y/size_x)\n",
        "print(size_y)\n",
        "\n",
        "Y = Y.reshape((size_x, size_y)) # Y is 29 times larger. Not sure what I did here. \n",
        "\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
        "\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "# rf=RandomForestClassifier(max_depth=8,n_estimators=5)\n",
        "\n",
        "# scores = cross_validate(lasso, X, Y, cv=3, scoring=('r2', 'neg_mean_squared_error'), return_train_score=True)\n",
        "\n",
        "\n",
        "reg_cv_score=cross_val_score(estimator=lin_reg,X=X_train,y=Y_train,cv=5)\n",
        "print(reg_cv_score) # Prints a bunch of NaNs currently.\n",
        "\n",
        "# errors = utils.cross_val(reg, X, y, n_folds=5, verbose=0)\n",
        "# utils.summarize_errors(errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9220, 1)\n",
            "39\n",
            "(9220, 1)\n",
            "(9220, 39)\n",
            "[nan nan nan nan nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uYM0wZGKFDK"
      },
      "source": [
        "The model has been built and trained on 2/3 of the data with a test on 1/3 of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXuXIaPzd9Dm"
      },
      "source": [
        "# When the dataframes are combined, use this code to select features.\n",
        "\n",
        "# features = ['SG', 'F', 'C', 'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT',\n",
        "#             'FTA', 'FGA', '3PA', 'DRB', 'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc',\n",
        "#             'ORB_perc', 'BLK_perc', 'TOV_perc', 'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']\n",
        "\n",
        "\n",
        "features = ['inj_FGA',\t'inj_FG_PCT',\t'inj_FG3A',\t'inj_FG3_PCT',\t'inj_FTA',\t'inj_FT_PCT',\t'inj_REB',\t'inj_AST',\t'inj_STL',\t\n",
        "            'inj_BLK',\t'inj_TO',\t'inj_PF', 'inj_PTS',\t'inj_PLUS_MINUS',\t'p5_MIN',\t\n",
        "            'p5_FGA',\t'p5_FG_PCT', \t'p5_FG3A', \t'p5_FG3_PCT',\t'p5_FTA',\t'p5_FT_PCT',\t'p5_REB',\n",
        "            'p5_AST',\t'p5_STL',\t'p5_BLK',\t'p5_TO',\t'p5_PF',\t'p5_PTS',\t'p5_PLUS_MINUS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2IhyvVJeK9m"
      },
      "source": [
        "# _all = ['Salary', 'Rest', 'Rota_All', 'Rota_Pos', 'Home', 'SG', 'F', 'C', 'Value', 'FPTS_std',\n",
        "#         'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT', 'FTA', 'FGA', '3PA', 'DRB',\n",
        "#         'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc', 'ORB_perc', 'BLK_perc', 'TOV_perc', \n",
        "#         'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s21vTbJeOWH",
        "outputId": "0d325b7d-ccbe-4f94-82be-4fa4ab9077a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "### Keeps Passing error of ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
        "### This should work when we start passing numbers. It will help pick best features.\n",
        "\n",
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "\n",
        "\n",
        "# df_baseline = df_Injury_End\n",
        "sort_by = 'Acquired'\n",
        "\n",
        "df_baseline = clean_dataset(df_baseline)\n",
        "#df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True, inplace=True)\n",
        "df_baseline.sort_values(by=[sort_by]).reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df_Injury_End.head)\n",
        "\n",
        "X = df_baseline.p5_PLUS_MINUS\n",
        "X = X.values.reshape(-1, 1)\n",
        "# X was called above\n",
        "\n",
        "# X = MinMaxScaler().fit_transform(X)\n",
        "# y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
        "\n",
        "Y = df_baseline.values.reshape(-1,1).flatten() # Y is 38 times larger. Not sure what I did here. \n",
        "Y = Y.reshape(-1, 1) \n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "size_x = X.shape[0]\n",
        "size_y = Y.shape[0]\n",
        "size_y = int(size_y/size_x)\n",
        "print(size_y)\n",
        "\n",
        "Y = Y.reshape((size_x, size_y))\n",
        "# Y = Y.reshape((16894, 38)) # Y is 38 times larger. Not sure what I did here. \n",
        "\n",
        "# Takes 2 minutes\n",
        "# clf.set_params(n_estimators=2000)\n",
        "# clf.fit(X, y, sample_weight=train_weight)\n",
        "\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X, Y)\n",
        "\n",
        "top_features = pd.Series(model.feature_importances_, index = _all).sort_values()\n",
        "top_features.plot(kind = \"barh\", figsize=(15,10) ,title='Top Features')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of Empty DataFrame\n",
            "Columns: [Unnamed: 0, Date, Team, Acquired, Relinquished, Notes, PLAYER_ID, TEAM_ID, NICKNAME, inj_MIN, inj_FGA, inj_FG_PCT, inj_FG3A, inj_FG3_PCT, inj_FTA, inj_FT_PCT, inj_REB, inj_AST, inj_STL, inj_BLK, inj_TO, inj_PF, inj_PTS, inj_PLUS_MINUS, p5_MIN, p5_FGA, p5_FG_PCT, p5_FG3A, p5_FG3_PCT, p5_FTA, p5_FT_PCT, p5_REB, p5_AST, p5_STL, p5_BLK, p5_TO, p5_PF, p5_PTS, p5_PLUS_MINUS]\n",
            "Index: []>\n",
            "(0, 1)\n",
            "(0, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-03670e5cf939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msize_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0msize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_y\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msize_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMmr36WK6P-h",
        "outputId": "1397da32-757a-4ffa-f9c7-433daed48468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "\n",
        "# lightgbm for regression\n",
        "\n",
        "X = df_baseline.p5_PLUS_MINUS\n",
        "X = X.values.reshape(-1, 1)\n",
        "\n",
        "Y = df_baseline.values.reshape(-1,1).flatten() # Y is 38 times larger. Not sure what I did here. \n",
        "Y = Y.reshape(-1, 1) \n",
        "\n",
        "size_x = X.shape[0]\n",
        "size_y = Y.shape[0]\n",
        "size_y = int(size_y/size_x)\n",
        "print(size_y)\n",
        "Y = Y.reshape((size_x, size_y))\n",
        "\n",
        "print(\"X Shape is \",X.shape)\n",
        "print(\"Y Shape is \",Y.shape)\n",
        "\n",
        "# Neat code from other write-up. This creates a dataset to define dataset\n",
        "# X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = LGBMRegressor()\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "### Searched Online. I need to use the TfidfVectorizer\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# tfidf = TfidfVectorizer(binary=True)\n",
        "# Y = tfidf.fit_transform(Y)\n",
        "\n",
        "n_scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# fit the model on the whole dataset\n",
        "model = LGBMRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "# make a single prediction. Code example is below:\n",
        "# row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
        "# yhat = model.predict(row)\n",
        "# print('Prediction: %.3f' % yhat[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "X Shape is  (201, 1)\n",
            "Y Shape is  (201, 39)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-593f0804dad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \"\"\"\n\u001b[1;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhzQuuh_eU9O"
      },
      "source": [
        "# omit_lowest = 20\n",
        "# _selected = list(top_features[omit_lowest:].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24geWtZsMKS2"
      },
      "source": [
        "# Building the Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AA48g-jftpp",
        "outputId": "194419b5-aa7e-4d5b-9648-65d8a7e7d934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "# Define Sequential model with 3 layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
        "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
        "        layers.Dense(4, name=\"layer3\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# x = df_baseline\n",
        "# x = tf.ones((3, 3))\n",
        "Y = model(X)\n",
        "\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 2.91940524e-07  3.08297296e-07 -3.65564912e-07 -7.21618691e-07]\n",
            " [ 2.91940524e-07  3.08297296e-07 -3.65564912e-07 -7.21618691e-07]\n",
            " [ 2.70738259e-05  2.85907116e-05 -3.39015655e-05 -6.69210926e-05]\n",
            " ...\n",
            " [ 2.18450302e-04  2.30689582e-04 -2.73541215e-04 -5.39965535e-04]\n",
            " [ 2.70726179e-05  2.85894359e-05 -3.39000528e-05 -6.69181066e-05]\n",
            " [ 2.18703317e-04  2.30956773e-04 -2.73858038e-04 -5.40590938e-04]], shape=(16894, 4), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLGlczbef3pZ"
      },
      "source": [
        "Insert Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQf0RZ8f20Z",
        "outputId": "7e108cdb-8616-4304-93ba-8e69b80257f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Create 3 layers\n",
        "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
        "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# Call layers on a test input\n",
        "# x = df_baseline\n",
        "Y = layer3(layer2(layer1(X)))\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]], shape=(16894, 4), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgrBDgnp_r-W"
      },
      "source": [
        "# Part 3 Conclusions\n",
        "\n",
        "This is where the conclusions section will be typed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne27vROk_r-W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}