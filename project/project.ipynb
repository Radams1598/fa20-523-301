{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cybertraining-dsc/fa20-523-301/blob/master/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZS0wkHPlyFO"
      },
      "source": [
        "# Final Project Notebook\n",
        "\n",
        "The report for this final project can be found at this [link](https://cybertraining-dsc.github.io/report/fa20-523-301/project/project/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvjolHp0lvEG"
      },
      "source": [
        "## Part 1 Importing the Functions and Building the Dataframes\n",
        "\n",
        "This file requires that we import Numpy, Matplotlib, Pylab, Keras, and Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBEQu5Gpl-eq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vccQxwMYw6l"
      },
      "source": [
        "An upload for the correct *.json file will need to occur. This file is what allows Kaggle to accept our credentials to download the correct datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxduR8dEBwvz",
        "outputId": "990858f4-73be-42d0-9ea5-e260afbebb7b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "##import the kaggle.json from local to drive\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8a28e0a-f133-49ef-8bb0-63d5e81bc9c7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a8a28e0a-f133-49ef-8bb0-63d5e81bc9c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hemmerleingavin\",\"key\":\"a0412c93ecb33476babdf128d77136c9\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jEmI1mIY9Ac"
      },
      "source": [
        "At this point we want to make our our own copy of the Kaggle files. This script also runs a test to ensure that it is working appropriately. The test is displayed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlgk1uL5D0Us",
        "outputId": "55fdcb20-8b8c-4fac-97f1-35895b62974b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "##make a kaggle and a data folder\n",
        "#!mkdir ~/.kaggle\n",
        "#!mkdir data\n",
        "##copy the kaggle.json to the .kaggle folder then grant permissions\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#test to see if kaggle is working, should print list of datasets\n",
        "!kaggle datasets list"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                               title                                                 size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------------  --------------------------------------------------  ------  -------------------  -------------  \n",
            "nehaprabhavalkar/indian-food-101                                  Indian Food 101                                        7KB  2020-09-30 06:23:43           3813  \n",
            "christianlillelund/donald-trumps-rallies                          Donald Trump's Rallies                               720KB  2020-09-26 10:25:08            987  \n",
            "heeraldedhia/groceries-dataset                                    Groceries dataset                                    257KB  2020-09-17 04:36:08           4616  \n",
            "andrewmvd/trip-advisor-hotel-reviews                              Trip Advisor Hotel Reviews                             5MB  2020-09-30 08:31:20           2680  \n",
            "balraj98/stanford-background-dataset                              Stanford Background Dataset                           17MB  2020-09-26 12:57:59            282  \n",
            "jilkothari/finance-accounting-courses-udemy-13k-course            Finance & Accounting Courses - Udemy (13K+ course)  1000KB  2020-09-17 12:46:12           1236  \n",
            "balraj98/massachusetts-roads-dataset                              Massachusetts Roads Dataset                            6GB  2020-09-26 03:57:49            241  \n",
            "arslanali4343/top-personality-dataset                             Top Personality Dataset                                9MB  2020-09-27 21:25:45           1525  \n",
            "oldaandozerskaya/fiction-corpus-for-agebased-text-classification  RusAge: Corpus for Age-Based Text Classification     509MB  2020-09-28 09:30:12             88  \n",
            "gpreda/chinese-mnist                                              Chinese MNIST                                         10MB  2020-08-05 12:36:00            519  \n",
            "gpreda/local-elections-romania-2020                               Local Elections Romania 2020                          28MB  2020-09-27 20:46:11            228  \n",
            "anth7310/mental-health-in-the-tech-industry                       Mental Health in the Tech Industry                     2MB  2020-09-27 11:17:23           2112  \n",
            "roshansharma/sanfranciso-crime-dataset                            Sanfranciso Crime Dataset                              6MB  2019-05-29 12:45:44           4995  \n",
            "bppuneethpai/tldr-summary-for-man-pages                           TLDR summary for man pages                             8MB  2020-09-25 09:50:10             57  \n",
            "sterby/german-recipes-dataset                                     German Recipes Dataset                                 5MB  2019-03-06 16:25:22            985  \n",
            "thomaskonstantin/top-270-rated-computer-science-programing-books  Top 270 Computer Science / Programing Books           45KB  2020-09-28 16:47:12            771  \n",
            "arslanali4343/real-estate-dataset                                 Real Estate DataSet                                   12KB  2020-09-28 21:25:33           1694  \n",
            "leangab/poe-short-stories-corpuscsv                               E.A. Poe's corpus of short stories                   725KB  2020-09-28 11:43:08            168  \n",
            "anmolkumar/health-insurance-cross-sell-prediction                 Health Insurance Cross Sell Prediction 🏠 🏥             6MB  2020-09-11 18:39:31           5074  \n",
            "ramjidoolla/ipl-data-set                                          IPL _Data_Set                                          1MB  2020-09-14 10:57:42           5163  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFgUWJo4ZJnV"
      },
      "source": [
        "These datasets are the files that the team used for the assignment. The first download is the injuries. This dataset will give a standard for when the injuries occured and the amount of time missed. The other two datasets are various statistics repositories for the players. Each of these are important to build the team's features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2QYBlpIEFBi",
        "outputId": "91d0dbe2-e2e2-42f9-d9ed-b486ab24a3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "##downloading all the datasets\n",
        "!kaggle datasets download -d ghopkins/nba-injuries-2010-2018\n",
        "!kaggle datasets download -d nathanlauga/nba-games\n",
        "!kaggle datasets download -d pablote/nba-enhanced-stats"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading nba-injuries-2010-2018.zip to /content\n",
            "\r  0% 0.00/226k [00:00<?, ?B/s]\n",
            "100% 226k/226k [00:00<00:00, 67.2MB/s]\n",
            "Downloading nba-games.zip to /content\n",
            " 50% 9.00M/18.1M [00:00<00:00, 11.2MB/s]\n",
            "100% 18.1M/18.1M [00:00<00:00, 20.7MB/s]\n",
            "Downloading nba-enhanced-stats.zip to /content\n",
            " 54% 9.00M/16.7M [00:01<00:00, 9.31MB/s]\n",
            "100% 16.7M/16.7M [00:01<00:00, 15.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3W0mASNHTs8",
        "outputId": "1fbfae05-b625-49ee-c72e-3198489c7005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "##unzipping to the data folder\n",
        "!unzip nba-injuries-2010-2018.zip -d data\n",
        "!unzip nba-games.zip -d data\n",
        "!unzip nba-enhanced-stats.zip -d data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  nba-injuries-2010-2018.zip\n",
            "  inflating: data/injuries_2010-2020.csv  \n",
            "Archive:  nba-games.zip\n",
            "  inflating: data/games.csv          \n",
            "  inflating: data/games_details.csv  \n",
            "  inflating: data/players.csv        \n",
            "  inflating: data/ranking.csv        \n",
            "  inflating: data/teams.csv          \n",
            "Archive:  nba-enhanced-stats.zip\n",
            "  inflating: data/2012-18_officialBoxScore.csv  \n",
            "  inflating: data/2012-18_playerBoxScore.csv  \n",
            "  inflating: data/2012-18_standings.csv  \n",
            "  inflating: data/2012-18_teamBoxScore.csv  \n",
            "  inflating: data/2016-17_officialBoxScore.csv  \n",
            "  inflating: data/2016-17_playerBoxScore.csv  \n",
            "  inflating: data/2016-17_standings.csv  \n",
            "  inflating: data/2016-17_teamBoxScore.csv  \n",
            "  inflating: data/2017-18_officialBoxScore.csv  \n",
            "  inflating: data/2017-18_playerBoxScore.csv  \n",
            "  inflating: data/2017-18_standings.csv  \n",
            "  inflating: data/2017-18_teamBoxScore.csv  \n",
            "  inflating: data/metadata_officialBoxScore.pdf  \n",
            "  inflating: data/metadata_playerBoxScore.pdf  \n",
            "  inflating: data/metadata_standing.pdf  \n",
            "  inflating: data/metadata_teamBoxScore.pdf  \n",
            "  inflating: data/teamBoxScore.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI8fIvIIZo_I"
      },
      "source": [
        "Now that the files are downloaded, the CSV's must be created into dataframes. These dataframes will be used to analyze the data and look at varying trends within the sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zmpmw-zImsz"
      },
      "source": [
        "#create a list for each data set\n",
        "ds_NBA_Injuries, ds_NBA_Games, ds_NBA_Enhanced = [], [], []\n",
        "\n",
        "#import csv files as dataframes and save to respective list, injury set first\n",
        "df_Injuries = pd.read_csv('data/injuries_2010-2020.csv')\n",
        "df_Injury_Start = df_Injuries[df_Injuries.Acquired.isnull()]\n",
        "df_Injury_End = df_Injuries[df_Injuries.Relinquished.isnull()]\n",
        "ds_NBA_Injuries = [df_Injury_Start, df_Injury_End]\n",
        "#nba games dataset\n",
        "df_Games_games = pd.read_csv('data/games.csv')\n",
        "df_Games_gamesDetails = pd.read_csv('data/games_details.csv')\n",
        "df_Games_players = pd.read_csv('data/players.csv')\n",
        "df_Games_ranking = pd.read_csv('data/ranking.csv')\n",
        "df_Games_teams = pd.read_csv('data/teams.csv')\n",
        "ds_NBA_Games = [df_Games_games, df_Games_gamesDetails, df_Games_players, df_Games_ranking, df_Games_teams]\n",
        "#nba enhanced stats dataset\n",
        "df_En_officialBS_1218 = pd.read_csv('data/2012-18_officialBoxScore.csv')\n",
        "df_En_playerBS_1218 = pd.read_csv('data/2012-18_playerBoxScore.csv')\n",
        "df_En_standings_1218 = pd.read_csv('data/2012-18_standings.csv')\n",
        "df_En_teamBS_1218 = pd.read_csv('data/2012-18_teamBoxScore.csv')  \n",
        "df_En_officialBS_1617 = pd.read_csv('data/2016-17_officialBoxScore.csv')  \n",
        "df_En_playerBS_1617 = pd.read_csv('data/2016-17_playerBoxScore.csv')\n",
        "df_En_standings_1617 = pd.read_csv('data/2016-17_standings.csv')\n",
        "df_En_teamBS_1617 = pd.read_csv('data/2016-17_teamBoxScore.csv')  \n",
        "df_En_officialBS_1718 = pd.read_csv('data/2017-18_officialBoxScore.csv')  \n",
        "df_En_playerBS_1718 = pd.read_csv('data/2017-18_playerBoxScore.csv')\n",
        "df_En_standings_1718 = pd.read_csv('data/2017-18_standings.csv')\n",
        "df_En_teamBS_1718 = pd.read_csv('data/2017-18_teamBoxScore.csv')  \n",
        "##data/metadata_officialBoxScore.pdf, data/metadata_playerBoxScore.pdf, data/metadata_standing.pdf, data/metadata_teamBoxScore.pdf  \n",
        "df_En_teamBS = pd.read_csv('data/teamBoxScore.csv')\n",
        "ds_NBA_Enhanced = [df_En_officialBS_1218, df_En_officialBS_1617, df_En_officialBS_1718, df_En_playerBS_1218, df_En_playerBS_1617, df_En_playerBS_1718, df_En_standings_1218, df_En_standings_1617, df_En_standings_1718, \\\n",
        "                       df_En_teamBS_1218, df_En_teamBS_1617, df_En_teamBS_1718, df_En_teamBS]\n",
        "\n",
        "\n",
        "#probably need some more data exploration and some feature engineering"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd4pQLvD_r-E"
      },
      "source": [
        "Setting up download function. This script will check to see if the filename has any data, and if it doesn't it will download from the specified url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZtWhqW6_r-E"
      },
      "source": [
        "def download(url, filename):\n",
        "    if len(filename.columns) >0:\n",
        "        n=0\n",
        "        #break\n",
        "    else: \n",
        "        #url=\"https://github.com/cs109/2014_data/blob/master/countries.csv\"\n",
        "        \n",
        "        s=requests.get(url).content\n",
        "        filename=pd.read_csv(url, error_bad_lines=False)\n",
        "        \n",
        "    return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpTr47oC_r-G"
      },
      "source": [
        "nBA_injuries = pd.DataFrame()\n",
        "nBA_games = pd.DataFrame()\n",
        "nBA_stats = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwXXoOYx_r-I",
        "outputId": "318630ff-6600-4887-ab2c-9b8eae5c7956"
      },
      "source": [
        "print(nBA_injuries)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3SK2S8-_r-K",
        "outputId": "a078cf11-f40d-4e25-fb37-64e8aeabcb86"
      },
      "source": [
        "url='https://www.kaggle.com/ghopkins/nba-injuries-2010-2018?select=injuries_2010-2020.csv'\n",
        "filename = nBA_injuries\n",
        "nBA_injuries = download(url, filename)\n",
        "\n",
        "url = 'https://www.kaggle.com/nathanlauga/nba-games?select=players.csv'\n",
        "filename = nBA_games\n",
        "nBA_games = download(url, filename)\n",
        "\n",
        "url = 'https://www.kaggle.com/pablote/nba-enhanced-stats?select=2012-18_playerBoxScore.csv'\n",
        "filename = nBA_stats\n",
        "nBA_stats = download(url, filename)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 6: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 3\\nSkipping line 10: expected 1 fields, saw 4\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 33: expected 1 fields, saw 8\\nSkipping line 42: expected 1 fields, saw 9\\nSkipping line 46: expected 1 fields, saw 2\\nSkipping line 47: expected 1 fields, saw 6\\nSkipping line 52: expected 1 fields, saw 2\\nSkipping line 53: expected 1 fields, saw 3\\nSkipping line 54: expected 1 fields, saw 2\\nSkipping line 55: expected 1 fields, saw 2\\nSkipping line 56: expected 1 fields, saw 2\\nSkipping line 78: expected 1 fields, saw 49\\nSkipping line 88: expected 1 fields, saw 2\\nSkipping line 89: expected 1 fields, saw 2\\nSkipping line 90: expected 1 fields, saw 2\\nSkipping line 91: expected 1 fields, saw 2\\nSkipping line 98: expected 1 fields, saw 2\\nSkipping line 100: expected 1 fields, saw 2\\nSkipping line 108: expected 1 fields, saw 2\\nSkipping line 169: expected 1 fields, saw 2\\nSkipping line 170: expected 1 fields, saw 2\\nSkipping line 171: expected 1 fields, saw 2\\nSkipping line 172: expected 1 fields, saw 2\\nSkipping line 174: expected 1 fields, saw 2\\nSkipping line 175: expected 1 fields, saw 2\\nSkipping line 194: expected 1 fields, saw 785\\nSkipping line 197: expected 1 fields, saw 2\\nSkipping line 198: expected 1 fields, saw 3\\nSkipping line 201: expected 1 fields, saw 2\\nSkipping line 203: expected 1 fields, saw 2\\nSkipping line 205: expected 1 fields, saw 5\\nSkipping line 206: expected 1 fields, saw 5\\nSkipping line 207: expected 1 fields, saw 2\\nSkipping line 209: expected 1 fields, saw 2\\nSkipping line 213: expected 1 fields, saw 2\\nSkipping line 214: expected 1 fields, saw 2\\nSkipping line 218: expected 1 fields, saw 2\\nSkipping line 221: expected 1 fields, saw 2\\nSkipping line 222: expected 1 fields, saw 2\\n'\n",
            "b'Skipping line 6: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 3\\nSkipping line 10: expected 1 fields, saw 4\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 33: expected 1 fields, saw 8\\nSkipping line 42: expected 1 fields, saw 9\\nSkipping line 46: expected 1 fields, saw 2\\nSkipping line 47: expected 1 fields, saw 6\\nSkipping line 52: expected 1 fields, saw 2\\nSkipping line 53: expected 1 fields, saw 3\\nSkipping line 54: expected 1 fields, saw 2\\nSkipping line 55: expected 1 fields, saw 2\\nSkipping line 56: expected 1 fields, saw 2\\nSkipping line 79: expected 1 fields, saw 51\\nSkipping line 89: expected 1 fields, saw 2\\nSkipping line 90: expected 1 fields, saw 2\\nSkipping line 91: expected 1 fields, saw 2\\nSkipping line 92: expected 1 fields, saw 2\\nSkipping line 99: expected 1 fields, saw 2\\nSkipping line 101: expected 1 fields, saw 2\\nSkipping line 109: expected 1 fields, saw 2\\nSkipping line 170: expected 1 fields, saw 2\\nSkipping line 171: expected 1 fields, saw 2\\nSkipping line 172: expected 1 fields, saw 2\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 175: expected 1 fields, saw 2\\nSkipping line 176: expected 1 fields, saw 2\\nSkipping line 195: expected 1 fields, saw 1120\\nSkipping line 198: expected 1 fields, saw 2\\nSkipping line 199: expected 1 fields, saw 3\\nSkipping line 202: expected 1 fields, saw 2\\nSkipping line 204: expected 1 fields, saw 2\\nSkipping line 206: expected 1 fields, saw 5\\nSkipping line 207: expected 1 fields, saw 5\\nSkipping line 208: expected 1 fields, saw 2\\nSkipping line 210: expected 1 fields, saw 2\\nSkipping line 214: expected 1 fields, saw 2\\nSkipping line 215: expected 1 fields, saw 2\\nSkipping line 219: expected 1 fields, saw 2\\nSkipping line 222: expected 1 fields, saw 2\\nSkipping line 223: expected 1 fields, saw 2\\n'\n",
            "b'Skipping line 6: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 5\\nSkipping line 10: expected 1 fields, saw 4\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 33: expected 1 fields, saw 8\\nSkipping line 42: expected 1 fields, saw 9\\nSkipping line 46: expected 1 fields, saw 2\\nSkipping line 47: expected 1 fields, saw 6\\nSkipping line 52: expected 1 fields, saw 2\\nSkipping line 53: expected 1 fields, saw 3\\nSkipping line 54: expected 1 fields, saw 2\\nSkipping line 55: expected 1 fields, saw 2\\nSkipping line 56: expected 1 fields, saw 2\\nSkipping line 79: expected 1 fields, saw 54\\nSkipping line 89: expected 1 fields, saw 2\\nSkipping line 90: expected 1 fields, saw 2\\nSkipping line 91: expected 1 fields, saw 2\\nSkipping line 92: expected 1 fields, saw 2\\nSkipping line 99: expected 1 fields, saw 2\\nSkipping line 101: expected 1 fields, saw 2\\nSkipping line 109: expected 1 fields, saw 2\\nSkipping line 170: expected 1 fields, saw 2\\nSkipping line 171: expected 1 fields, saw 2\\nSkipping line 172: expected 1 fields, saw 2\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 175: expected 1 fields, saw 2\\nSkipping line 176: expected 1 fields, saw 2\\nSkipping line 195: expected 1 fields, saw 1381\\nSkipping line 198: expected 1 fields, saw 2\\nSkipping line 199: expected 1 fields, saw 3\\nSkipping line 202: expected 1 fields, saw 2\\nSkipping line 204: expected 1 fields, saw 2\\nSkipping line 206: expected 1 fields, saw 5\\nSkipping line 207: expected 1 fields, saw 5\\nSkipping line 208: expected 1 fields, saw 2\\nSkipping line 210: expected 1 fields, saw 2\\nSkipping line 214: expected 1 fields, saw 2\\nSkipping line 215: expected 1 fields, saw 2\\nSkipping line 219: expected 1 fields, saw 2\\nSkipping line 222: expected 1 fields, saw 2\\nSkipping line 223: expected 1 fields, saw 2\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLp742E5ftIr"
      },
      "source": [
        "# Part 2 Building the Keras Model\n",
        "\n",
        "A link for Keras for us to use can be found [here](https://keras.io/guides/sequential_model/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AA48g-jftpp"
      },
      "source": [
        "# Define Sequential model with 3 layers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
        "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
        "        layers.Dense(4, name=\"layer3\"),\n",
        "    ]\n",
        ")\n",
        "# Call model on a test input\n",
        "x = tf.ones((3, 3))\n",
        "y = model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLGlczbef3pZ"
      },
      "source": [
        "Insert Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQf0RZ8f20Z"
      },
      "source": [
        "# Create 3 layers\n",
        "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
        "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
        "layer3 = layers.Dense(4, name=\"layer3\")\n",
        "\n",
        "# Call layers on a test input\n",
        "x = tf.ones((3, 3))\n",
        "y = layer3(layer2(layer1(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgrBDgnp_r-W"
      },
      "source": [
        "# Part 3 Conclusions\n",
        "\n",
        "This is where the conclusions section will be typed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne27vROk_r-W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}